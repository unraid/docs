---
sidebar_position: 3
sidebar_label: Cache pools
---

import RemoveDiskGui from './partials/remove-disk-gui.mdx';
import RemoveDiskCommandLine from './partials/remove-disk-command-line.mdx';
import PoolSingleDeviceMode from './partials/pool-single-device-mode.mdx';
import PoolMultiDeviceMode from './partials/pool-multi-device-mode.mdx';
import MovePoolToArray from './partials/move-pool-to-array.mdx';
import MoveArrayToPool from './partials/move-array-to-pool.mdx';
import MoveBetweenPoolsUsingMover from './partials/move-between-pools-using-mover.mdx';
import MoveBetweenPoolsManual from './partials/move-between-pools-manual.mdx';

# Cache pools

In Unraid, a %%cache pool|cache-pool%% is a collection of one or more drives, typically SSDs or high-speed HDDs. These drives temporarily store data before it's moved to your main [%%array|array%%](./array/overview.mdx). Using %%cache pools|cache-pool%% can significantly enhance write speeds, protect your data, and provide dedicated storage for specific tasks like running Docker containers or [%%virtual machines|vm%%](../create-virtual-machines/overview-and-system-prep.mdx).

%%Cache pools|cache-pool%% offer several advantages, making them a valuable addition to your Unraid setup, such as:

1. **Faster write speeds:** %%Cache pools|cache-pool%% allow you to quickly write data to faster drives before it gets transferred to the main %%array|array%%. This greatly enhances perceived performance when saving files.

2. **Data protection for cached files:** By using multiple drives in a %%cache pool|cache-pool%% (like setting them up in %%RAID 1|raid1%%), you add redundancy. This means your cached data is protected from drive failure before it even reaches the main %%array|array%%.

3. **Optimized storage for applications:** Storing applications like Docker containers or %%virtual machines|vm%% on a %%cache pool|cache-pool%% improves their performance, reduces wear on your main %%array|array%%, and minimizes the time it takes to access frequently-used files.

4. **Flexible and dedicated storage:** With multiple %%cache pools|cache-pool%%, you can assign specific pools for different tasks. For instance, you could have one pool dedicated to downloads and another for %%virtual machines|vm%%, reducing competition for resources and boosting efficiency.

:::info[Keep in Mind]

- **Multiple pools:** You can create and name different %%cache pools|cache-pool%%, tailoring them to match your specific needs.
- **SSD vs. HDD:** SSDs are great for speed, while you can use HDDs for large, sequential data workloads. Additionally, HDDs can help prolong the lifespan of your SSDs.
- **Redundancy matters:** To protect your data, use more than one drive in a %%cache pool|cache-pool%%. A single drive pool won't protect you from potential drive failure.
- **File system choice:** The default file system for %%cache pools|cache-pool%% is %%BTRFS|btrfs%%, which supports various %%RAID|raid%% options for added redundancy and flexibility. For more details on file system selection, see [File systems](./file-systems.mdx).
- **%%Mover|mover%% integration:** Data written to a %%cache pool|cache-pool%% is automatically transferred to your main %%array|array%% based on a schedule you set. This keeps your [%%user shares|user-share%%](./shares.mdx) organized and easy to manage.
- **Application performance:** By placing Docker containers, app data, and %%VM|vm%% disks on a %%cache pool|cache-pool%%, you enhance access speed and minimize strain on your main storage.

:::

---

## Pool modes

Unraid %%cache pools|cache-pool%% can operate in two main modes: **single device mode** and **multi-device mode**. Knowing the difference between these modes will help you find the right balance between performance, flexibility, and data protection for your needs.

### Single device mode

<PoolSingleDeviceMode />

### Multi-device mode

<PoolMultiDeviceMode />

Common tasks for the %%cache pool|cache-pool%% include:

- Switching between single and multi-device modes
- Adding disks to a pool
- Replacing disks in a pool
- Moving files between the pool and the %%array|array%% (see [Moving files between a pool and the array](#moving-files-between-a-pool-and-the-array))

---

## Switching to Multi-Device Mode

%%Cache pools|cache-pool%% in Unraid can be expanded from a single device to multiple devices, allowing for increased capacity and redundancy. To take advantage of multi-device mode, your pool must be formatted as %%BTRFS|btrfs%% or %%ZFS|zfs%%.

### Converting a pool to BTRFS or ZFS

If your %%cache pool|cache-pool%% isn't already formatted as %%BTRFS|btrfs%% or %%ZFS|zfs%%, you can convert it using the following steps.

To convert a pool to BTRFS or ZFS:

1. Back up important content. See [Moving files between a pool and the array](#moving-files-between-a-pool-and-the-array) to move files from your pool to the %%array|array%%.
2. Stop the %%array|array%%.
3. In the **Main** tab, click the pool and select **BTRFS** or **ZFS** as the file system format.
4. Start the %%array|array%%.
5. When the pool shows as **unmountable**, confirm and click **Format**.
6. After formatting, you’ll have a %%BTRFS|btrfs%% or %%ZFS|zfs%% pool (single device at this stage).
7. (Optional) Add additional drives as needed.
8. Restore your data by moving files back to the pool.

### Adding drives to create a multi-device pool

Once your pool is formatted as %%BTRFS|btrfs%% or %%ZFS|zfs%%, you can add more drives for redundancy and to expand storage. For detailed instructions on adding disks to existing pools, see [Adding disks to a pool](#adding-disks-to-a-pool).

To add more drives for redundancy:

1. Stop the %%array|array%%.
2. In the **Main** tab, assign one or more new devices to your pool.
3. Start the %%array|array%%.
4. Unraid automatically incorporates the new devices and starts a **balance** (%%BTRFS|btrfs%%) or **resilver** (%%ZFS|zfs%%).
5. In the **Main** tab, click the first pool device and check **Balance Status** (%%BTRFS|btrfs%%) or **zpool status** (%%ZFS|zfs%%) to follow progress.
6. When complete, the pool operates in **multi-device mode** with enhanced capacity and redundancy.

:::tip

You can use the [BTRFS Disk Usage Calculator](http://carfax.org.uk/btrfs-usage/) to estimate available space and redundancy based on your chosen %%RAID|raid%% level and device sizes.

:::

---

## Adding disks to a pool

As your storage needs grow, you may want to expand your cache pool by adding additional disks. This process allows you to increase both capacity and performance while maintaining data protection through RAID configurations.

:::note

If you want to add disks to your pool, make sure your pool is already formatted as %%BTRFS|btrfs%% or %%ZFS|zfs%%. If it's not, you'll need to format it first, as explained in [Converting a pool to BTRFS or ZFS](#converting-a-pool-to-btrfs-or-zfs).

:::

### BTRFS pools

To add a disk to a %%BTRFS|btrfs%% pool:

1. Stop the %%array|array%%.
2. In the **Main** tab, open the pool.
3. In the **Pool Devices** section, set **Slots** to the exact number of additional devices.
4. Assign the new devices to the available slots.
5. Start the %%array|array%% to enable the changes.

:::note

After starting the %%array|array%%, %%BTRFS|btrfs%% automatically begins a **Balance** operation to redistribute data across all devices in the pool. This process may take several hours or even days, depending on the size of your pool and the amount of data stored. During this time, your pool may appear busy, but you can continue using it normally. You can monitor the Balance progress in the **Main** tab by clicking the first pool device and checking **Balance Status**.

:::

### ZFS pools

Expanding %%ZFS|zfs%% pools depends on your type of pool configuration:

- **Single-vdev RAIDZ1/2/3 pools:** A pool with one group of drives in a RAIDZ configuration. Can be expanded one drive at a time. See [RAIDZ expansion](#raidz-expansion) below.
- **Mirrored pools:** A pool where drives are paired together in mirrors. Can add additional mirror pairs to increase capacity.
- **Multi-vdev pools:** A pool with multiple groups of drives (e.g., multiple RAIDZ groups or multiple mirror pairs). Cannot be expanded by adding individual drives to existing groups.

:::important

Not all %%ZFS|zfs%% pools can be expanded by adding devices. Only single-vdev RAIDZ1/2/3 pools allow for one-drive-at-a-time expansion. Other pool configurations require you to add complete vdevs, such as adding a new mirror pair to a mirrored pool or adding a new vdev of the same width to a RAIDZ pool.

:::

:::tip[Planning for future expansion]

If you're creating a new two-device %%ZFS|zfs%% pool and plan to expand it later by adding drives one at a time, choose **RAIDZ1** during initial setup instead of the default mirrored configuration. While two-device pools default to mirrored (which provides redundancy), choosing RAIDZ1 allows you to expand the pool incrementally in the future without migrating your data. If you're not planning to expand beyond two drives, the default mirrored configuration is recommended for its simplicity and performance.

:::

#### RAIDZ expansion

Starting with Unraid 7.2, you can expand single-vdev RAIDZ1/2/3 pools one drive at a time. This feature allows you to grow your pool capacity incrementally without rebuilding the entire pool.

To expand a single-vdev RAIDZ pool:

1. With the %%array|array%% running, on ***Main → Pool Devices***, select the pool name to view the details.
2. In the **Pool Status** area, check for an **Upgrade Pool** button. If one exists, you'll need to click that before continuing. Note that upgrading the pool will limit your ability to downgrade to earlier releases of Unraid.
3. Stop the %%array|array%%.
4. On ***Main → Pool Devices***, add a slot to the pool.
5. Select the appropriate drive (must be at least as large as the smallest drive in the pool).
6. Start the %%array|array%%.

:::caution

If you see an "invalid expansion" warning, the pool needs to be upgraded first using the **Upgrade Pool** button mentioned in step 2.

:::

---

## Removing disks from a pool

Removing a disk from a %%BTRFS|btrfs%% or %%ZFS|zfs%% multi-device %%cache pool|cache-pool%% can help you reclaim hardware, replace a failing drive, or reconfigure your storage. This process is only possible if your pool is set up for redundancy (like %%RAID 1|raid1%% for both data and metadata) and the remaining devices have enough space to hold all of your data.

### Using the WebGUI

<RemoveDiskGui />

### Using the command line (Advanced)

<RemoveDiskCommandLine />

### Changing pool RAID levels

%%BTRFS|btrfs%% provides the ability to change %%RAID|raid%% levels for %%cache pools|cache-pool%% dynamically, allowing you to adjust settings without stopping the %%array|array%% or losing any data. This flexibility lets you optimize for performance, redundancy, or storage efficiency as your requirements change. For information on adding disks to %%BTRFS|btrfs%% pools, see [BTRFS pools](#btrfs-pools).

<h4>Supported %%RAID|raid%% Levels</h4>

| %%RAID\|raid%% Level | Data Protection | Space Efficiency | Use Case                                                                                       |
| -------------------- | --------------- | ---------------- | ---------------------------------------------------------------------------------------------- |
| Single               | None            | 100%             | Temporary storage or non-critical data where redundancy isn't needed.                          |
| %%RAID 0\|raid0%%    | None            | 100%             | Maximizes performance and capacity, but not recommended for critical data.                     |
| %%RAID 1\|raid1%%    | 1 disk failure  | 50%              | Default for Unraid pools. Ideal for Docker/%%VM\|vm%% storage and critical data.               |
| %%RAID 10\|raid10%%  | 1 disk failure  | 50%              | Combines %%RAID 0\|raid0%% speed with %%RAID 1\|raid1%% redundancy for high-performance needs. |
| %%RAID 5\|raid5%%\*  | 1 disk failure  | 67-94%           | **Experimental.** Balances capacity and redundancy for large media storage.                    |
| %%RAID 6\|raid6%%\*  | 2 disk failures | 50-88%           | **Experimental.** Provides extra protection for archival storage with large drives.            |

:::important

%%RAID 5|raid5%% and %%RAID 6|raid6%% are considered experimental in %%BTRFS|btrfs%%. %%ZFS|zfs%% provides more mature support for these %%RAID|raid%% levels. Use with caution and ensure you have backups. Avoid using experimental %%RAID|raid%% levels for critical data.

:::

To change a pool's %%RAID|raid%% level:

1. Start the %%array|array%% in normal mode.
2. In the **Main** tab, click the pool name.
3. Scroll to **Balance Status** to view current %%RAID|raid%% levels for data and metadata.
4. Select the new %%RAID|raid%% profile from the drop-down.
5. Click **Balance** to begin the conversion.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![Converting from %%RAID 1|raid1%% to Single profile](/img/Btrfs-raid1.jpg)
  <p class="caption-center">*Example: Converting from %%RAID 1|raid1%% to Single profile*</p>
</div>

6. Monitor progress in the %%WebGUI|web-gui%%.

:::note[Timing]

Balance operations can take several hours to days, depending on the amount of data in the pool, drive speeds, and the complexity of the selected %%RAID|raid%% level.

:::

<details>
  <summary>Troubleshooting balance operations if stuck - Click to expand/collapse</summary>

  If a balance operation seems stuck or unresponsive, follow these steps:

  1. In ***Tools → Logs***, filter for `btrfs` entries.
  2. Stop and resume the operation:
     - Click **Cancel Balance**.
     - Restart the %%array|array%%.
     - Initiate the balance operation again.
  3. Run %%SMART|smart%% tests on all devices in the pool. For more information on disk health monitoring, see [SMART reports and disk health](../../system-administration/monitor-performance/smart-reports-and-disk-health.mdx).
  4. Ensure there is at least 10-15% free space available on the pool.
  5. If issues persist, share the logs on the [Unraid forums](https://forums.unraid.net/). For guidance on capturing diagnostics, see [Capture diagnostics and logs](../../troubleshooting/diagnostics/capture-diagnostics-and-logs.mdx).

</details>

For advanced %%BTRFS|btrfs%% configuration details, refer to the [BTRFS wiki](https://btrfs.wiki.kernel.org/index.php/Using_Btrfs_with_Multiple_Devices).

---

## Replace a disk in a pool

Replacing a disk in your %%cache pool|cache-pool%% is an important task that helps maintain the performance and reliability of your storage system.

:::note[Prerequisites]

- **Check your pool configuration:** Make sure your pool is set up with a redundant %%RAID|raid%% profile, like %%RAID 1|raid1%%. You can do this by going to ***Main → Pool → Balance Status*** (for %%BTRFS|btrfs%%) or ZFS pool status (for %%ZFS|zfs%%) in your management interface.
- **Choose the right replacement disk:** The new disk must be the same size or larger than the one you're replacing.
- **Hot-swap capability:** If your hardware supports hot-swapping, you won't need to power down your system to replace the disk.

:::

To replace a disk in a pool:

1. In the **Main** tab, stop the %%array|array%% (Array Operation → **Stop**).
2. (Optional) If you don’t have hot-swap, physically remove the old disk.
3. Install the replacement disk and ensure proper connection.
4. Refresh the **Main** tab to detect the new disk.
5. Assign the new disk to the previous slot.
6. Start the %%array|array%%.
7. Monitor the rebuild progress in the %%WebGUI|web-gui%%.

:::important[Timing]

Rebuilding can take some time, depending on the size of the disk and the current load on your system. For example, rebuilding a 4TB SSD in a %%RAID 1|raid1%% setup may take approximately 3-6 hours. It's a good idea to plan this when you can allow the system to work uninterrupted.

:::

---

## Minimum free space for a cache pool

Setting a minimum free space for your %%cache pool|cache-pool%% can provide better control over file placement, especially when dealing with large files like high-resolution videos. This setting helps Unraid know when to stop writing to the pool and start writing directly to the larger storage %%array|array%%, avoiding interruptions or data corruption.

:::tip[Example]

If you often download files around 10 GB, set the minimum free space to at least 10 GB, but ideally 20 GB to allow for adjustments.

:::

You can access Minimum free space by clicking on the pool name in the **Main** tab and going to **Individual Pool Settings**.

<h4>How it works</h4>

- When you transfer a file to a share that includes a pool, Unraid will respect the first floor setting it encounters (either the share's minimum free space or the pool's minimum free space, whichever is reached first).
- The minimum free space setting tells Unraid to stop using the %%cache pool|cache-pool%% when free space drops below this amount.
- If your share uses a %%cache pool|cache-pool%% as **Primary storage**, files go to the pool until it reaches the minimum free space, then they are sent directly to the %%array|array%%.
- If set to use a %%cache pool|cache-pool%% exclusively (no **Secondary storage**), this setting is not applied.
- If set to use only the %%array|array%% as **Primary storage**, files go straight to the %%array|array%%.

:::tip[Use case example]

Media share has the floor set to 20GB, which is appropriate for the files in that share. However, if you also use the pool for a VM and want to leave a cushion in case the vdisk grows, you could set the pool floor to 50GB. This way, any transfer to the Media share after the pool has less than 50GB free would go directly to the array.

:::

:::tip[Best practice]

Set the minimum free space to at least the size of the largest file you expect, preferably double that size. For example, if your largest file is 30 GB, set the minimum to 60 GB.

:::

:::caution

**Do not set the minimum free space to 0.** This can cause disk full errors. Always use a reasonable value.

:::

---

## Moving files between a pool and the array

There are times when you may need to move files between your %%cache pool|cache-pool%% and the main %%array|array%%, such as when preparing for maintenance, upgrading hardware, or optimizing performance. This process is also useful for backing up your %%cache pool|cache-pool%% before making configuration changes or replacing drives. Unraid provides a built-in tool called %%Mover|mover%% to automate this process for [%%user shares|user-share%%](./shares.mdx).

:::tip

Always disable Docker and %%VM|vm%% services before moving files with the %%Mover|mover%%. This prevents open files from being skipped during the transfer.

:::

### Move from pool to array

<MovePoolToArray />

### Move from array to pool

<MoveArrayToPool />

<details>
  <summary><strong>Why do files sometimes end up in the wrong pool or cache?</strong> - Click to expand/collapse</summary>

  When you move files between [%%user shares|user-share%%](./shares.mdx) at the Linux level (for example, using `mv` or within a Docker container), Linux tries to optimize the operation. If both the source and destination appear on the same mount point (`/mnt/user`), Linux might rename the file instead of moving it. This can result in files remaining on the original disk or pool, even if the share's "Use cache" setting is set to "No."

  To ensure that files move as intended, consider the following options:

  - Use the %%Mover|mover%% tool.
  - Copy files and then delete the originals.
  - Move files over the network.

  These methods help prevent files from ending up in the wrong location.

</details>

---

## Multiple pools

Unraid allows you to create and manage up to 35 separate storage pools, each with up to 60 devices. Multiple pools give you flexibility to allocate storage for different tasks, improve performance, and customize redundancy based on your needs. Each pool can use a different file system, %%RAID|raid%% level, and device type (SSD, HDD, NVMe, etc.).

<h4>Why use multiple pools?</h4>

- **Optimize performance:** Separate pools for %%VMs|vm%%, Docker containers, downloads, or media can enhance speed and reduce conflicts.
- **Protect data:** Assign different %%RAID|raid%% levels or file systems to each pool for tailored redundancy and backup options.
- **Isolate workloads:** Keep critical applications on faster, redundant pools and store bulk data on larger, cost-effective devices.
- **Manage flexibly:** You can expand, reduce, or format pools independently without impacting others.

<h4>Common use cases</h4>

| Use case                     | Configuration example                                                      | Benefit                               |
| ---------------------------- | -------------------------------------------------------------------------- | ------------------------------------- |
| High-performance %%VMs\|vm%% | NVMe SSD pool, %%RAID 1\|raid1%%, %%BTRFS\|btrfs%% or %%ZFS\|zfs%%         | Fast I/O with redundancy              |
| Docker/Appdata storage       | SSD pool, %%RAID 1\|raid1%%, %%BTRFS\|btrfs%% or %%ZFS\|zfs%%              | Quick access and data protection      |
| Bulk media downloads         | Large HDD pool, %%RAID 0\|raid0%% or single, %%XFS\|xfs%%/%%BTRFS\|btrfs%% | High capacity with less redundancy    |
| Project/Team isolation       | Separate pools for each team/project                                       | Reduces resource conflicts            |
| Snapshots and backup targets | %%ZFS\|zfs%% pool, %%RAIDZ1\|raidz1%%/%%RAIDZ2\|raidz2%% (multi-device)    | Supports native snapshots and backups |

:::info[Supported File Systems]

- %%BTRFS|btrfs%%: Best for multi-device pools (supports %%RAID 0|raid0%%, %%RAID 1|raid1%%, %%RAID 10|raid10%%, %%RAID 5|raid5%%, %%RAID 6|raid6%%).
- %%ZFS|zfs%%: Excellent for both single and multi-device pools (Unraid 6.12+), with mature support for %%RAIDZ1|raidz1%% and %%RAIDZ2|raidz2%%. For advanced ZFS features and configuration, see [ZFS storage](../../advanced-configurations/optimize-storage/zfs-storage.mdx).
- %%XFS|xfs%%: Suitable for single-device pools.

:::

When accessing a [%%user share|user-share%%](./shares.mdx) from multiple pools and %%array|array%% disks, Unraid merges the directory listings in this order:

1. Pool assigned to the share
2. %%Array|array%% disks (disk1, disk2, ..., disk28)
3. Other pools (in order)

### Moving files between pools

Unraid doesn't allow direct file movement between pools through the %%WebGUI|web-gui%%, but you can do it using the %%Mover|mover%% tool or via command line.

:::note[Remember]

If any of the files belong to a Docker container and/or %%VM|vm%%, the services must be disabled for the files to be moved successfully.

:::

### Using Mover

<MoveBetweenPoolsUsingMover />

### Manual file transfer (Advanced)

<MoveBetweenPoolsManual />

:::warning

If you remove a device from a %%BTRFS|btrfs%% or %%ZFS|zfs%% pool and move it to a new pool, Unraid will erase all data on it when the %%array|array%% restarts. Always back up important data before changing pool configurations.

:::
