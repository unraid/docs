---
sidebar_position: 1
sidebar_label: ZFS-Speicher
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# ZFS-Speicher

:::important[Special Danke]
Wir möchten unseren Dank an Ed Rawlings (\[Spaceinvader One])([https://www.youtube.com/c/SpaceinvaderOne](https://www.youtube.com/c/SpaceinvaderOne)) für das Fachwissen und die Anleitung zum Ausdruck bringen, von denen diese %%ZFS|zfs%%-Speicherdokumentation angepasst wurde. Seine Tutorials und Erkenntnisse haben zahllosen Unraid-Nutzern geholfen, fortgeschrittene Speichertechniken zu meistern. Wir schätzen seine anhaltenden Beiträge zur Unraid-Gemeinschaft sehr.
:::

%%ZFS|zfs%% bringt fortschrittliche Datenintegrität, flexible Speicher-Konfigurationen und hohe Leistung in Ihr Unraid-System. Dieser Leitfaden erklärt die grundlegenden Konzepte von %%ZFS|zfs%% und führt Sie durch die Verwaltung von %%ZFS|zfs%%-Pools direkt über das Unraid %%WebGUI|web-gui%%. Egal, ob Sie einen neuen %%ZFS|zfs%%-Speicher einrichten oder einen bestehenden Pool integrieren, Sie finden hier die notwendigen Schritte und den Kontext, um sicher anzufangen.

---

## Warum ZFS?

ZFS ist ein modernes Dateisystem und Volume-Manager, der Ihre Daten schützt, Korruption verhindert und die Speicherverwaltung vereinfacht.

Mit ZFS erhalten Sie:

- Automatische Datenintegritätschecks und Selbstheilung
- Eingebaute RAID-Unterstützung (Spiegelungen, RAIDZ)
- %%Snapshots|snapshot%% und Klone für einfache Backups und Rollbacks
- ZFS send/receive für effiziente Replikation
- Kompression in Echtzeit

Unraid supports %%ZFS|zfs%% for any storage pool. You can create a new %%ZFS|zfs%% pool, import one from another system, or use Unraid’s unique hybrid %%ZFS|zfs%% setup: add a %%ZFS|zfs%%-formatted disk directly to the Unraid %%array|array%% (not a pool) and combine %%ZFS|zfs%% features with Unraid’s %%parity|parity%% protection.

:::info\[Example]

You can use %%ZFS|zfs%% %%snapshots|snapshot%% and replication on a single disk as a backup target, or replicate a fast SSD %%ZFS|zfs%% pool to a %%ZFS|zfs%% disk in the %%array|array%% protected by Unraid %%parity|parity%% - getting the best of both worlds.

:::

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs1.png)
</div>

:::note
The hybrid %%ZFS|zfs%%-in-array approach is helpful for specific backup or replication scenarios but is not a replacement for a full %%ZFS|zfs%% pool. %%ZFS|zfs%% disks in the %%array|array%% are managed individually; you do not get the combined performance, redundancy, or self-healing of a true multi-disk %%ZFS|zfs%% pool. For full %%ZFS|zfs%% functionality, always use dedicated %%ZFS|zfs%% pools.
:::

### Pools, Vdevs und Redundanz

Ein %%ZFS|zfs%%-Pool (genannt "Zpool") besteht aus einem oder mehreren Vdevs (virtuellen Geräten). Jedes Vdev ist eine Gruppe physischer Festplatten mit einem eigenen Redundanzgrad. %%ZFS|zfs%% schreibt Daten über Vdevs hinweg, aber jedes Vdev ist für seine eigene Fehlertoleranz verantwortlich.

:::caution
Redundanz ist immer pro VDEV gegeben. Wenn ein VDEV ausfällt, fällt der gesamte Pool aus, selbst wenn andere VDEVs gesund sind. Planen Sie Ihre VDEVs sorgfältig!
:::

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs2.png)
</div>

---

## Erstellen eines ZFS-Pools

So erstellen Sie einen ZFS-Pool über das WebGUI:

1. Stoppen Sie das %%array|array%%.
2. **Pool hinzufügen** klicken.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs3.png)
</div>

3. Wählen Sie einen Namen für Ihren Pool (zum Beispiel `raptor`).
4. Stellen Sie die Anzahl der Slots auf die Anzahl der Festplatten ein, die Sie in Ihren primären Daten-Vdev(s) haben möchten.

:::note
Diese anfängliche Slot-Anzahl ist nur für Daten-VDEVs gedacht. Support-VDEVs (wie Protokoll- oder Cache-Laufwerke) können separat hinzugefügt werden, nachdem der Pool erstellt wurde.
:::

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs4.png)
</div>

5. Weisen Sie dem Pool Festplatten zu (die Reihenfolge spielt keine Rolle).

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs5.png)
</div>

6. Klicken Sie auf den Pool-Namen (z.B. `raptor`), um den Konfigurationsbildschirm zu öffnen.
7. Stellen Sie den Dateisystemtyp auf `zfs` oder `zfs-verschlüsselt` (für LUKS-Verschlüsselung) ein.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs6.png)
</div>

8. Wählen Sie Ihr Zuordnungsprofil - dies bestimmt die Redundanz und Leistung Ihres Pools.

:::tip
Überprüfen Sie vor dem Abschluss die Abschnitte über Zuordnungsprofile und Topologie, um eine fundierte Entscheidung zu treffen.
:::

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs7.png)
</div>

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs8.png)
</div>

9. Aktivieren Sie die Komprimierung, wenn gewünscht (empfohlen für die meisten Workloads).
10. Klicken Sie auf **Erledigt**, dann starten Sie das %%array|array%%.

---

## Eine ZFS-Disk ins Array integrieren (Hybrid-Setup)

You can add a standalone %%ZFS|zfs%% disk to your Unraid %%array|array%% (not a %%ZFS|zfs%% pool) to combine %%ZFS|zfs%% features with Unraid's %%parity|parity%% protection.

:::info[What dies ermöglicht]
- **Parity-Schutz:** Die ZFS-Festplatte ist durch die %%array|array%%-%%parity|parity%% von Unraid geschützt, wodurch Ihre Daten vor einzelnen (oder mehreren, abhängig von Ihren %%parity drives|parity-drives%%) Festplattenausfällen gesichert sind.

- **Datenintegrität:** %%ZFS|zfs%% bietet Integritätsprüfungen auf Blockebene (Prüfsummen). Während eine einzelne Festplatte Bit Rot nicht selbstständig heilen kann, wird %%ZFS|zfs%% Korruption erkennen und Sie alarmieren, damit Sie aus dem Backup wiederherstellen können, bevor ein stiller Datenverlust auftritt.

- **%%ZFS|zfs%% features:** You can utilize %%ZFS|zfs%% %%snapshots|snapshot%% and replication on this disk, making it ideal for backup targets, specific datasets, or scenarios where you want %%ZFS|zfs%% features alongside traditional Unraid storage.
:::

To add a %%ZFS|zfs%% disk to the %%array|array%%:

1. Gehen Sie zum **Main**-Tab im %%WebGUI|web-gui%%.
2. Stoppen Sie das %%array|array%%.
3. Klicken Sie auf einen leeren Slot unter **Array Devices**.
4. Wählen Sie die Festplatte aus, die Sie hinzufügen möchten.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs9.png)
</div>

5. Wählen Sie unter **Dateisystem** `zfs` oder `zfs-verschlüsselt`.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs10.png)
</div>

6. Klicken Sie auf **Übernehmen**.
7. Starten Sie das %%array|array%% und lassen Sie die Festplatte bei Bedarf formatieren.

---

## Wahl eines Zuordnungsprofils

Wenn Sie einen %%ZFS|zfs%%-Pool einrichten, bestimmt Ihr Zuweisungsprofil, wie Ihre Daten geschützt werden, wie Ihr Pool performt und wie Sie ihn erweitern können. Hier ist ein einfacher Vergleich, der Ihnen hilft zu entscheiden, welches Profil Ihren Bedürfnissen entspricht:

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs11.png)
</div>

| Profil  | Redundanz                    | Leistung                                                                          | Erweiterung                      | Speichereffizienz | Typischer Anwendungsfall                   |
| ------- | ---------------------------- | --------------------------------------------------------------------------------- | -------------------------------- | ----------------- | ------------------------------------------ |
| Stripe  | Keine                        | Schnell, aber riskant                                                             | Hinzufügen von mehr Festplatten  | 100%              | Temporärer/zwischengespeicherter Speicher  |
| Spiegel | 1:1 (%%RAID 1\|raid1%%-Stil) | Hervorragend für zufällige I/O                                                    | Hinzufügen von mehr Spiegelungen | 50%               | Hohe Leistung, einfache Erweiterung        |
| RAIDZ1  | 1 Festplatte pro Vdev        | Schnell für große Dateien. Nicht ideal für kleine oder zufällige Schreibvorgänge. | Neue Vdevs hinzufügen            | Hoch              | Allgemeine Nutzung, 1-Festplatten-Toleranz |
| RAIDZ2  | 2 Festplatten pro Vdev       | Wie Z1, aber leicht langsamere Schreibvorgänge (zusätzliche Parität)              | Neue Vdevs hinzufügen            | Mäßig             | Wichtige Daten, 2-Festplatten-Toleranz     |
| RAIDZ3  | 3 Festplatten pro Vdev       | Wie Z2, mit mehr Schreibaufwand (für maximale Sicherheit)                         | Neue Vdevs hinzufügen            | Niedriger         | Mission-kritisch, 3-Festplatten-Toleranz   |

:::important[How wählen]
- Verwenden Sie **Mirror**, wenn Sie die beste Leistung und einfache, flexible Erweiterung wünschen und es Ihnen nichts ausmacht, mehr Speicherplatz für Redundanz zu nutzen.
- Wählen Sie **RAIDZ1/2/3**, wenn Sie den nutzbaren Speicher maximieren und große Dateien speichern möchten, beachten Sie jedoch, dass die Erweiterung weniger flexibel ist und die Leistung bei zufälligem Schreiben geringer ist.
- **Stripe** ist nur für nicht-kritische, temporäre Daten geeignet – bei Ausfall einer Festplatte verlieren Sie alles.
:::

---

## Topologie und Erweiterung

Wie Sie Festplatten in Vdevs gruppieren, beeinflusst sowohl die Datensicherheit als auch die Geschwindigkeit.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs12.png)
</div>

- Wenn Sie alle Festplatten in einem großen RAIDZ2-Vdev einfügen, können Sie zwei beliebige Festplatten ohne Datenverlust verlieren. Die Erweiterung bedeutet jedoch, dass man ein weiteres vollständiges Vdev hinzufügen muss.
- Sie erzielen bessere Parallelleistung, wenn Sie Festplatten in mehrere kleinere RAIDZ1-Vdevs aufteilen. Seien Sie vorsichtig; wenn im selben Vdev zwei Festplatten ausfallen, verlieren Sie den gesamten Pool.
- ZFS streift Daten über Vdevs, nicht einzelne Festplatten, daher können mehr Vdevs bei Workloads mit vielen kleinen Dateien oder zufälligen I/O zu besseren Leistungen führen.
- Das Erweitern eines ZFS-Pools bedeutet in der Regel das Hinzufügen eines neuen Vdevs mit demselben Layout, nicht nur einer einzelnen Festplatte.

:::tip
Plan your pool’s layout to fit your needs and future growth. Unlike the Unraid %%array|array%%, you can’t add a single disk to an existing vdev using the %%WebGUI|web-gui%%.
:::

---

## Kompression und RAM

%%ZFS|zfs%% offers advanced features that can significantly improve Unraid's storage efficiency and performance. Two common topics of interest are compression and memory requirements.

ZFS-Kompression arbeitet transparent – sie funktioniert im Hintergrund und schrumpft Daten, bevor sie die Festplatte erreicht.

Dies bietet zwei wesentliche Vorteile:

- **Reduzierte Festplattennutzung:** Weniger Speicherplatz wird genutzt.
- **Verbesserte Leistung:** Weniger Daten zu schreiben und zu lesen kann zu schnelleren Vorgängen führen, besonders bei modernen CPUs.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs13.png)
</div>

:::tip
Aktivieren Sie die %%ZFS|zfs%%-Komprimierung für die meisten Unraid-%%ZFS|zfs%%-Pools. Sie ist sicher, effizient und beeinträchtigt selten Kompatibilität oder Stabilität.
:::

<details>
  <summary><strong>Der ZFS RAM-Mythos</strong> - Klicken, um ein-/auszuklappen</summary>

  Möglicherweise sind Sie auf den veralteten Rat gestoßen: „ZFS benötigt 1 GB RAM pro 1 TB Speicher.“ Dies gilt für die meisten Benutzer nicht mehr. ZFS nutzt RAM für seinen Adaptive Replacement Cache (ARC), der häufig zugegriffene Lesevorgänge beschleunigt.

  Unraid begrenzt ZFS automatisch auf einen angemessenen Teil des Arbeitsspeichers Ihres Systems (in der Regel 1/8 des gesamten RAM). Dies ermöglicht es ZFS, ohne Beeinträchtigung der Docker-Container, VMs oder des Unraid-Betriebssystems gut zu funktionieren.

  <div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
    ![](/img/zfs14.png)
  </div>
</details>

:::info
%%ZFS|zfs%% skaliert gut mit dem verfügbaren Speicher. Mehr RAM kann die Cache-Performance verbessern, aber %%ZFS|zfs%% arbeitet zuverlässig mit bescheidener Hardware. Lassen Sie sich von alten Empfehlungen nicht davon abhalten, %%ZFS|zfs%% auf Unraid zu nutzen.
:::

---

## Importieren von auf anderen Systemen erstellten ZFS-Pools

Unraid kann mit minimalem Aufwand ZFS-Pools importieren, die auf anderen Plattformen erstellt wurden.

<details>
  <summary><strong>So importieren Sie einen ZFS-Pool</strong> - Klicken, um ein-/auszuklappen</summary>

  1. **Array stoppen:** Stellen Sie sicher, dass Ihr Unraid-%%array|array%% angehalten ist.
  2. **Neuen Pool hinzufügen:** Klicken Sie auf **Pool hinzufügen**.
  3. **Alle Laufwerke zuweisen:**
     - Stellen Sie **Anzahl der Daten-Slots** auf die Gesamtzahl der Laufwerke in Ihrem ZFS-Pool ein (einschließlich Daten-Vdevs und Support-Vdevs).
     - Weisen Sie jedem Laufwerk den richtigen Slot zu.
     - *Beispiel:* Für einen Pool mit einem 4-Laufwerke gespiegelt vdev und einem 2-Laufwerke L2ARC vdev, setzen Sie 6 Slots und weisen Sie allen sechs Laufwerken zu.
  4. **Stellen Sie Dateisystem auf "Auto":** Klicken Sie auf den Pool-Namen (z.B. `raptor`) und stellen Sie **Dateisystem** auf **Auto**.
  5. **Abschließen und Array starten:** Klicken Sie auf **Erledigt**, dann starten Sie das %%array|array%%.

  :::info[Automatische Erkennung]
  Unraid wird das ZFS-Pool automatisch erkennen und importieren. Unterstützende vdevs (wie Log, Cache/L2ARC, Special/Dedup) werden unter **Subpools** im WebGUI aufgelistet. Es ist nicht erforderlich, Subpools nach Initiierung des Imports separat hinzuzufügen. Unraid wird sie automatisch zusammen mit den Hauptdatenträgern importieren, wenn alle erforderlichen Laufwerke zugewiesen sind.
  :::

  Es wird dringend empfohlen, nach dem Import einen %%scrub|scrub%% durchzuführen, um die Datenintegrität zu überprüfen.

  - Klicken Sie auf den Poolnamen (z.B. `raptor`), um seine Konfiguration zu öffnen.
  - Unter **Poolstatus** den Status überprüfen und auf **Scrub** klicken.

  <div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
    ![](/img/zfs15.png)
  </div>
</details>

---

## Unterstützende vdevs (Unterpools)

Unraid bezeichnet %%ZFS|zfs%%-unterstützende Vdevs als Subpools. Die meisten Nutzer benötigen diese **nicht**, aber fortgeschrittene Nutzer könnten ihnen begegnen:

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs16.png)
</div>

| Unterstützender vdev (Unterpool) | Zweck                                            | Risiko/Notizen                                                                                                             |
| -------------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------- |
| Spezial-vdev                     | Speichert Metadaten und kleine Dateien           | Der Pool wird unlesbar, wenn verloren.                                                                                     |
| Dedup vdev                       | Ermöglicht Deduplizierung                        | Benötigt große Mengen RAM; riskant für die meisten Nutzer. Vermeiden Sie es, es sei denn, Sie haben spezielle Bedürfnisse. |
| Log vdev (SLOG)                  | Verbessert die Synchronisierungs-Schreibleistung | Optional. Nur vorteilhaft für bestimmte Arbeitslasten.                                                                     |
| Cache vdev (L2ARC)               | Bietet SSD-basierten Lese-Cache                  | Optional. Kann die Leseraten für große Arbeitsmengen verbessern.                                                           |
| Ersatz vdev                      | In Unraid nicht unterstützt (ab 7.1.2)           |                                                                                                                            |

:::caution
Die meisten Unraid-Nutzer sollten unterstützende Vdevs/Subpools vermeiden, es sei denn, Sie haben spezielle und gut verstandene Bedürfnisse. Sie sind für spezialisierte Arbeitslasten ausgelegt und können Komplexität oder Risiken einführen, wenn sie missbraucht werden.
:::

---

## Kritische unterstützende vdev-Laufwerke beim Import nicht zugewiesen

When you import a %%ZFS|zfs%% pool into Unraid, you need to assign every drive from your original pool, including those used for support vdevs, to the pool slots. Unraid will automatically recognize each drive’s role (data, log, cache, special, or dedup) once the %%array|array%% starts. You don’t need to specify which drive serves what purpose manually.

Wenn Sie vergessen, ein Laufwerk, das Teil eines unterstützenden vdev war, beim Import einzubeziehen, hängt das Ergebnis von der Funktion des vdev ab:

| vdev-Typ                     | Wenn das Laufwerk beim Import fehlt                                        | Ergebnis                                                                                                                                                     |
| ---------------------------- | -------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Spezial-vdev oder Dedup vdev | Pool wird nicht importiert oder ist unbenutzbar                            | Diese Vdevs speichern kritische Metadaten oder Deduplizierungstabellen. Ohne sie kann %%ZFS\|zfs%% den Pool nicht sicher mounten.                            |
| Log (SLOG) vdev              | Pool wird importiert, aber die Synchronisierungs-Schreibleistung nimmt ab. | Der Pool bleibt zugänglich, aber Sie könnten eine langsamere Leistung für Arbeitslasten bemerken, die auf Synchronisierungs-Schreibvorgänge angewiesen sind. |
| Cache (L2ARC) vdev           | Pool wird importiert, aber der Lese-Cache geht verloren                    | Der Pool funktioniert normal, aber Sie verlieren den Leistungsboost durch den L2ARC-Cache. Keine Daten gehen verloren.                                       |

:::tip
Weisen Sie beim Import in Unraid immer alle physischen Laufwerke aus Ihrem ursprünglichen %%ZFS|zfs%%-Pool zu, einschließlich aller unterstützenden Vdevs. Dies gewährleistet eine reibungslose Erkennung und Integration. Für neue Pools, die in Unraid erstellt werden, sind unterstützende Vdevs optional und im Allgemeinen für die meisten Nutzer nicht erforderlich.
:::

---

## Speicher erweitern

%%ZFS|zfs%% ist mächtig, aber es ist wichtig zu verstehen, wie seine Speichererweiterung funktioniert - besonders wenn Sie zukünftiges Wachstum planen.

Historisch gesehen haben %%ZFS|zfs%%-Vdevs eine feste Breite. Sie können keine Festplatte zu einem bestehenden RAIDZ-Vdev hinzufügen, um es zu vergrößern.

Möglichkeiten zur Erweiterung Ihres Pools umfassen:

- **Hinzufügen eines neuen Vdev:** Erweitern Sie Ihren Pool, indem Sie ein weiteres Vdev hinzufügen (wie eine neue Spiegelung oder RAIDZ-Gruppe). Dies erhöht die Kapazität, aber Sie müssen Festplatten in Sets hinzufügen, die der Konfiguration des Vdevs entsprechen.
- **Ersetzen von Laufwerken durch größere:** Tauschen Sie jedes Laufwerk in einem Vdev nacheinander gegen eine größere Festplatte aus. Siehe [Laufwerkaustausch](../../using-unraid-to/manage-storage/array-configuration.mdx#replacing-faileddisabled-disks) für detaillierte Verfahren. Nachdem alle Laufwerke ersetzt wurden und der Pool sich aufgelöst hat, erhöht sich die Kapazität des Vdevs.
- **Erstellen eines neuen Pools:** Das Starten eines neuen %%ZFS|zfs%% Pools hält Dinge für verschiedene Datentypen oder Arbeitslasten organisiert und unabhängig.

:::tip[Planning vorwärts]
Bevor Sie Ihren Pool aufbauen, überlegen Sie, wie viel Speicher Sie benötigen werden - nicht nur heute, sondern auch in Zukunft. %%ZFS|zfs%% belohnt gute Planung, besonders wenn Sie disruptive Upgrades später vermeiden möchten.
:::

---

## Die Verwendung von ZFS-Pools auf einem vorhandenen Unraid-Server

Wenn Sie ein traditionelles Unraid %%array|array%% laufen haben und %%ZFS|zfs%% Pools hinzufügen möchten, finden Sie hier einige effektive Möglichkeiten, sie zu integrieren:

| Anwendungsfall                                          | Beschreibung                                                                                                                                                                                       | Details / Beispiele                                                                                                           |
| ------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| Schneller SSD/NVMe-Pool für App-Daten & Docker          | Store the appdata share for fast, responsive containers and databases. This supports %%snapshot\|snapshot%%s for easy rollbacks and can also host %%VM\|vm%%s for high I/O.                        | Viele Nutzer wählen hierfür einen 2-Festplatten-%%ZFS\|zfs%%-Spiegel. Es ist einfach zu erweitern und bietet starke Leistung. |
| ZFS-Pool für wichtige Daten                             | Use a %%ZFS\|zfs%% mirror or RAIDZ2 pool for irreplaceable files like photos, tax records, and %%user share\|user-share%% data. %%ZFS\|zfs%% checks for corruption and self-heals with redundancy. | Dieses Setup schützt kritische Daten mit automatischen Integritätsüberprüfungen und Selbstheilungsmöglichkeiten.              |
| Tägliches Backup oder Replikationsziel                  | Use a %%ZFS\|zfs%% disk (even within the Unraid %%array\|array%%) as a replication target. You can replicate other pools locally or from another Unraid server.                                    | Nutzen Sie `zfs send/receive` oder Tools wie Syncoid für schnelle und zuverlässige Backups und Wiederherstellungen.           |
| %%Snapshot\|snapshot%%-basierter Wiederherstellungspool | Keep point-in-time %%snapshot\|snapshot%%s of critical data or containers. %%snapshot\|snapshot%%s can be auto-scheduled and are space-efficient.                                                  | Diese Funktion ermöglicht eine schnelle Wiederherstellung nach versehentlichen Löschungen oder Fehleinstellungen.             |

## Vermeidung häufiger ZFS-Fehler

%%ZFS|zfs%% ist ein leistungsfähiges Dateisystem, aber es gibt mehrere häufige Fallstricke, die seine Vorteile untergraben können. Es ist wichtig, die folgenden Punkte zu beachten, bevor Sie Ihren Pool konfigurieren für eine reibungslosere Erfahrung:

- **Unterschiede in der Festplattengröße in RAIDZ:** %%ZFS|zfs%% behandelt alle Festplatten in einem RAIDZ-Vdev als die Größe der kleinsten. Um die beste Effizienz zu gewährleisten, verwenden Sie immer identisch große Laufwerke in jedem Vdev.

- **Erweiterung von RAIDZ-Vdevs über das %%WebGUI|web-gui%%:** Während Unraid 7.1.x und neuer die Erweiterung von RAIDZ über die Befehlszeile unterstützt, ist diese Funktion im %%WebGUI|web-gui%% noch nicht verfügbar. Verwenden Sie vorerst die CLI, um zu erweitern, oder fügen Sie neue Vdevs über das GUI hinzu.

- **%%ZFS|zfs%% disk vs. full zpool:** A single %%ZFS|zfs%%-formatted disk in the Unraid %%array|array%% does not offer the redundancy or features of a dedicated %%ZFS|zfs%% pool. To leverage advanced functionality, use standalone pools.

- **Deduplizierung ohne ausreichenden RAM:** Deduplizierung erfordert erheblichen Speicher, und wenn Sie es ohne genügend RAM aktivieren, kann die Leistung erheblich beeinträchtigt werden. Aktivieren Sie die Deduplizierung nur, wenn Sie die Anforderungen vollständig verstehen.

- **Vdev-Redundanz ist lokal:** Die Redundanz in %%ZFS|zfs%% ist lokal für jedes Vdev und wird nicht über den Pool verteilt. Stellen Sie sicher, dass Sie Ihr Vdev-Layout planen, um das gewünschte Maß an Belastbarkeit zu erreichen.
