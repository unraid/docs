---
sidebar_position: 1
sidebar_label: ZFS-Speicher
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# ZFS-Speicher

:::important[Special Danke]
Wir möchten unseren Dank an Ed Rawlings (\[Spaceinvader One])([https://www.youtube.com/c/SpaceinvaderOne](https://www.youtube.com/c/SpaceinvaderOne))) für das Fachwissen und die Anleitung zum Ausdruck bringen, von denen diese %%ZFS|zfs%%-Speicherdokumentation angepasst wurde. Seine Tutorials und Erkenntnisse haben zahllosen Unraid-Nutzern geholfen, fortgeschrittene Speichertechniken zu meistern. Wir schätzen seine anhaltenden Beiträge zur Unraid-Gemeinschaft sehr.
:::

%%ZFS|zfs%% bietet erweiterte Datenintegrität, flexible Speicherlösungen und hohe Leistung für Ihr Unraid-System. Dieser Leitfaden erklärt die Kernkonzepte von %%ZFS|zfs%% und führt Sie durch die Verwaltung von %%ZFS|zfs%%-Pools direkt über das Unraid %%WebGUI|web-gui%%. Egal, ob Sie neuen %%ZFS|zfs%%-Speicher einrichten oder einen bestehenden Pool integrieren, hier finden Sie die Schritte und den Kontext, die Sie benötigen, um sicher zu starten.

---

## Warum ZFS?

ZFS ist ein modernes Dateisystem und Volume-Manager, der Ihre Daten schützt, Korruption verhindert und die Speicherverwaltung vereinfacht.

Mit ZFS erhalten Sie:

- Automatische Datenintegritätschecks und Selbstheilung
- Eingebaute RAID-Unterstützung (Spiegelungen, RAIDZ)
- %%Snapshots|snapshot%% und Klone für einfache Backups und Rollbacks
- ZFS send/receive für effiziente Replikation
- Kompression in Echtzeit

Unraid supports %%ZFS|zfs%% for any storage pool. You can create a new %%ZFS|zfs%% pool, import one from another system, or use Unraid’s unique hybrid %%ZFS|zfs%% setup: add a %%ZFS|zfs%%-formatted disk directly to the Unraid %%array|array%% (not a pool) and combine %%ZFS|zfs%% features with Unraid’s %%parity|parity%% protection.

:::info\[Example]

You can use %%ZFS|zfs%% %%snapshots|snapshot%% and replication on a single disk as a backup target, or replicate a fast SSD %%ZFS|zfs%% pool to a %%ZFS|zfs%% disk in the %%array|array%% protected by Unraid %%parity|parity%% - getting the best of both worlds.

:::

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs1.png)
</div>

:::note
The hybrid %%ZFS|zfs%%-in-array approach is helpful for specific backup or replication scenarios but is not a replacement for a full %%ZFS|zfs%% pool. %%ZFS|zfs%% disks in the %%array|array%% are managed individually; you do not get the combined performance, redundancy, or self-healing of a true multi-disk %%ZFS|zfs%% pool. For full %%ZFS|zfs%% functionality, always use dedicated %%ZFS|zfs%% pools.
:::

### Pools, Vdevs und Redundanz

Ein %%ZFS|zfs%%-Pool (genannt „zpool“) besteht aus einem oder mehreren vdevs (virtuelle Geräte). Jedes vdev ist eine Gruppe physischer Festplatten mit einem eigenen Redundanzlevel. %%ZFS|zfs%% schreibt Daten über vdevs, aber jedes vdev ist für seine Ausfallsicherheit verantwortlich.

:::caution
Redundanz gilt immer pro vdev. Wenn ein vdev ausfällt, fällt der gesamte Pool aus, auch wenn andere vdevs gesund sind. Planen Sie Ihre vdevs sorgfältig!
:::

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs2.png)
</div>

---

## Erstellen eines ZFS-Pools

So erstellen Sie einen ZFS-Pool über das WebGUI:

1. Stoppen Sie das %%array|array%%.
2. **Pool hinzufügen** klicken.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs3.png)
</div>

3. Wählen Sie einen Namen für Ihren Pool (zum Beispiel `raptor`).
4. Stellen Sie die Anzahl der Slots auf die Anzahl der Festplatten ein, die Sie in Ihren primären Daten-Vdev(s) haben möchten.

:::note
Diese anfängliche Steckplatzanzahl gilt nur für Daten-vdevs. Unterstützungs-vdevs (wie Protokoll- oder Cache-Laufwerke) können nach der Erstellung des Pools separat hinzugefügt werden.
:::

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs4.png)
</div>

5. Weisen Sie dem Pool Festplatten zu (die Reihenfolge spielt keine Rolle).

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs5.png)
</div>

6. Klicken Sie auf den Pool-Namen (z.B. `raptor`), um den Konfigurationsbildschirm zu öffnen.
7. Stellen Sie den Dateisystemtyp auf `zfs` oder `zfs-verschlüsselt` (für LUKS-Verschlüsselung) ein.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs6.png)
</div>

8. Wählen Sie Ihr Zuordnungsprofil - dies bestimmt die Redundanz und Leistung Ihres Pools.

:::tip
Überprüfen Sie vor dem Abschluss die Abschnitte über Zuordnungsprofile und Topologie, um eine fundierte Entscheidung zu treffen.
:::

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs7.png)
</div>

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs8.png)
</div>

9. Aktivieren Sie die Komprimierung, wenn gewünscht (empfohlen für die meisten Workloads).
10. Klicken Sie auf **Erledigt**, dann starten Sie das %%array|array%%.

---

## Eine ZFS-Disk ins Array integrieren (Hybrid-Setup)

You can add a standalone %%ZFS|zfs%% disk to your Unraid %%array|array%% (not a %%ZFS|zfs%% pool) to combine %%ZFS|zfs%% features with Unraid's %%parity|parity%% protection.

:::info[What this enables]
- **Parity-Schutz:** Die ZFS-Festplatte ist durch die %%array|array%%-%%parity|parity%% von Unraid geschützt, wodurch Ihre Daten vor einzelnen (oder mehreren, abhängig von Ihren %%parity drives|parity-drives%%) Festplattenausfällen gesichert sind.

- **Datenintegrität:** %%ZFS|zfs%% bietet Integritätsprüfungen auf Blockebene (Prüfsummen). Während eine einzelne Festplatte nicht zur Selbstheilung von Bitrot fähig ist, erkennt %%ZFS|zfs%% Korruption und warnt Sie, sodass Sie vor einem schleichenden Datenverlust aus einem Backup wiederherstellen können.

- **%%ZFS|zfs%% features:** You can utilize %%ZFS|zfs%% %%snapshots|snapshot%% and replication on this disk, making it ideal for backup targets, specific datasets, or scenarios where you want %%ZFS|zfs%% features alongside traditional Unraid storage.
:::

To add a %%ZFS|zfs%% disk to the %%array|array%%:

1. Gehen Sie zum **Main**-Tab im %%WebGUI|web-gui%%.
2. Stoppen Sie das %%array|array%%.
3. Klicken Sie auf einen leeren Slot unter **Array Devices**.
4. Wählen Sie die Festplatte aus, die Sie hinzufügen möchten.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs9.png)
</div>

5. Wählen Sie unter **Dateisystem** `zfs` oder `zfs-verschlüsselt`.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs10.png)
</div>

6. Klicken Sie auf **Übernehmen**.
7. Starten Sie das %%array|array%% und lassen Sie die Festplatte bei Bedarf formatieren.

---

## Wahl eines Zuordnungsprofils

Wenn Sie einen %%ZFS|zfs%%-Pool einrichten, bestimmt Ihr Zuweisungs-Profil, wie Ihre Daten geschützt werden, wie Ihr Pool performt und wie Sie ihn erweitern können. Hier ist ein einfacher Vergleich, der Ihnen hilft zu entscheiden, welches Profil am besten zu Ihren Anforderungen passt:

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs11.png)
</div>

| Profil  | Redundanz                    | Leistung                                                                          | Erweiterung                      | Speichereffizienz | Typischer Anwendungsfall                   |
| ------- | ---------------------------- | --------------------------------------------------------------------------------- | -------------------------------- | ----------------- | ------------------------------------------ |
| Stripe  | Keine                        | Schnell, aber riskant                                                             | Hinzufügen von mehr Festplatten  | 100%              | Temporärer/zwischengespeicherter Speicher  |
| Spiegel | 1:1 (%%RAID 1\|raid1%%-Stil) | Hervorragend für zufällige I/O                                                    | Hinzufügen von mehr Spiegelungen | 50%               | Hohe Leistung, einfache Erweiterung        |
| RAIDZ1  | 1 Festplatte pro Vdev        | Schnell für große Dateien. Nicht ideal für kleine oder zufällige Schreibvorgänge. | Neue Vdevs hinzufügen            | Hoch              | Allgemeine Nutzung, 1-Festplatten-Toleranz |
| RAIDZ2  | 2 Festplatten pro Vdev       | Wie Z1, aber leicht langsamere Schreibvorgänge (zusätzliche Parität)              | Neue Vdevs hinzufügen            | Mäßig             | Wichtige Daten, 2-Festplatten-Toleranz     |
| RAIDZ3  | 3 Festplatten pro Vdev       | Wie Z2, mit mehr Schreibaufwand (für maximale Sicherheit)                         | Neue Vdevs hinzufügen            | Niedriger         | Mission-kritisch, 3-Festplatten-Toleranz   |

:::important[How to choose]
- Verwenden Sie **Mirror**, wenn Sie die beste Leistung und einfache, flexible Erweiterung wünschen und es Ihnen nichts ausmacht, mehr Speicherplatz für Redundanz zu nutzen.
- Wählen Sie **RAIDZ1/2/3**, wenn Sie den nutzbaren Speicher maximieren und große Dateien speichern möchten, beachten Sie jedoch, dass die Erweiterung weniger flexibel ist und die Leistung bei zufälligem Schreiben geringer ist.
- **Stripe** ist nur für nicht-kritische, temporäre Daten geeignet – bei Ausfall einer Festplatte verlieren Sie alles.
:::

---

## Topologie und Erweiterung

Wie Sie Festplatten in Vdevs gruppieren, beeinflusst sowohl die Datensicherheit als auch die Geschwindigkeit.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs12.png)
</div>

- Wenn Sie alle Laufwerke in ein großes RAIDZ2-vdev einfügen, können Sie zwei beliebige Laufwerke verlieren, ohne Daten zu verlieren. Eine Erweiterung bedeutet jedoch das Hinzufügen eines weiteren vollständigen vdevs.
- Sie gewinnen eine bessere parallele Leistung, wenn Sie Laufwerke in mehrere kleinere RAIDZ1-vdevs aufteilen. Seien Sie vorsichtig; wenn zwei Laufwerke im selben vdev ausfallen, verlieren Sie den gesamten Pool.
- ZFS streift Daten über Vdevs, nicht einzelne Festplatten, daher können mehr Vdevs bei Workloads mit vielen kleinen Dateien oder zufälligen I/O zu besseren Leistungen führen.
- Das Erweitern eines ZFS-Pools bedeutet in der Regel das Hinzufügen eines neuen Vdevs mit demselben Layout, nicht nur einer einzelnen Festplatte.

:::tip
Plan your pool’s layout to fit your needs and future growth. Unlike the Unraid %%array|array%%, you can’t add a single disk to an existing vdev using the %%WebGUI|web-gui%%.
:::

---

## Kompression und RAM

%%ZFS|zfs%% bietet erweiterte Funktionen, die die Speichereffizienz und Leistung von Unraid erheblich verbessern können. Zwei gängige Interessensthemen sind Komprimierung und Speicheranforderungen.

ZFS-Kompression arbeitet transparent – sie funktioniert im Hintergrund und schrumpft Daten, bevor sie die Festplatte erreicht.

Dies bietet zwei wesentliche Vorteile:

- **Reduzierte Festplattennutzung:** Weniger Speicherplatz wird genutzt.
- **Verbesserte Leistung:** Weniger Daten zu schreiben und zu lesen kann zu schnelleren Vorgängen führen, besonders bei modernen CPUs.

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs13.png)
</div>

:::tip
Aktivieren Sie die %%ZFS|zfs%%-Komprimierung für die meisten Unraid %%ZFS|zfs%%-Pools. Sie ist sicher, effizient und beeinträchtigt selten die Kompatibilität oder Stabilität.
:::

<details>
  <summary><strong>Der ZFS RAM-Mythos</strong> - Klicken, um ein-/auszuklappen</summary>

  Vielleicht sind Sie auf die veraltete Empfehlung gestoßen: „%%ZFS|zfs%% benötigt 1 GB RAM pro 1 TB Speicher.“ Dies ist für die meisten Benutzer nicht mehr zutreffend. %%ZFS|zfs%% nutzt RAM für seinen Adaptive Replacement Cache (ARC), der häufig abgerufene Lesevorgänge beschleunigt.

  Unraid beschränkt %%ZFS|zfs%% automatisch auf die Nutzung eines angemessenen Teils des RAM Ihres Systems (in der Regel 1/8 des gesamten RAM). Dies ermöglicht, dass %%ZFS|zfs%% gut performt, ohne Docker-Container, %%VMs|vm%% oder das Unraid-Betriebssystem zu beeinträchtigen.

  <div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
    ![](/img/zfs14.png)
  </div>
</details>

:::info
%%ZFS|zfs%% skaliert gut mit verfügbarem Speicher. Mehr RAM kann die Cache-Leistung verbessern, aber %%ZFS|zfs%% funktioniert zuverlässig mit bescheidenen Hardwarevoraussetzungen. Lassen Sie sich durch alte Empfehlungen nicht davon abhalten, %%ZFS|zfs%% auf Unraid zu verwenden.
:::

---

## Importieren von auf anderen Systemen erstellten ZFS-Pools

Unraid kann mit minimalem Aufwand ZFS-Pools importieren, die auf anderen Plattformen erstellt wurden.

<details>
  <summary><strong>So importieren Sie einen ZFS-Pool</strong> - Klicken, um ein-/auszuklappen</summary>

  1. **Array stoppen:** Stellen Sie sicher, dass Ihr Unraid-%%array|array%% angehalten ist.
  2. **Neuen Pool hinzufügen:** Klicken Sie auf **Pool hinzufügen**.
  3. **Alle Laufwerke zuweisen:**
     - Stellen Sie **Anzahl der Daten-Slots** auf die Gesamtzahl der Laufwerke in Ihrem ZFS-Pool ein (einschließlich Daten-Vdevs und Support-Vdevs).
     - Weisen Sie jedem Laufwerk den richtigen Slot zu.
     - *Beispiel:* Für einen Pool mit einem 4-Laufwerke gespiegelt vdev und einem 2-Laufwerke L2ARC vdev, setzen Sie 6 Slots und weisen Sie allen sechs Laufwerken zu.
  4. **Stellen Sie Dateisystem auf "Auto":** Klicken Sie auf den Pool-Namen (z.B. `raptor`) und stellen Sie **Dateisystem** auf **Auto**.
  5. **Abschließen und Array starten:** Klicken Sie auf **Erledigt**, dann starten Sie das %%array|array%%.

  :::info[Automatische Erkennung]
  Unraid erkennt und importiert den %%ZFS|zfs%%-Pool automatisch. Unterstützungs-vdevs (wie Log, Cache/L2ARC, Special/Dedup) werden unter **Subpools** im %%WebGUI|web-gui%% aufgelistet. Es ist nicht erforderlich, Subpools nach dem Start des Imports separat hinzuzufügen. Unraid importiert sie automatisch zusammen mit den Hauptdatenträgern, wenn alle erforderlichen Laufwerke zugewiesen sind.
  :::

  Es wird dringend empfohlen, nach dem Import einen %%scrub|scrub%% durchzuführen, um die Datenintegrität zu überprüfen.

  - Klicken Sie auf den Poolnamen (z.B. `raptor`), um seine Konfiguration zu öffnen.
  - Unter **Poolstatus** den Status überprüfen und auf **Scrub** klicken.

  <div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
    ![](/img/zfs15.png)
  </div>
</details>

---

## Unterstützende vdevs (Unterpools)

Unraid bezeichnet %%ZFS|zfs%%-Unterstützungs-vdevs als Subpools. Die meisten Benutzer benötigen diese **nicht**, aber fortgeschrittene Benutzer könnten ihnen begegnen:

<div style={{ margin: 'auto', maxWidth: '600px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![](/img/zfs16.png)
</div>

| Unterstützender vdev (Unterpool) | Zweck                                            | Risiko/Notizen                                                                                                                       |
| -------------------------------- | ------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------ |
| Spezial-vdev                     | Speichert Metadaten und kleine Dateien           | Der Pool wird unlesbar, wenn verloren.                                                                                               |
| Dedup vdev                       | Ermöglicht Deduplizierung                        | Erfordert große Mengen an RAM; riskant für die meisten Benutzer. Vermeiden Sie dies, es sei denn, Sie haben spezifische Bedürfnisse. |
| Log vdev (SLOG)                  | Verbessert die Synchronisierungs-Schreibleistung | Optional. Nur vorteilhaft für bestimmte Arbeitslasten.                                                                               |
| Cache vdev (L2ARC)               | Bietet SSD-basierten Lese-Cache                  | Optional. Kann die Lesegeschwindigkeit für große Arbeitsmengen verbessern.                                                           |
| Ersatz vdev                      | In Unraid nicht unterstützt (ab 7.1.2)           |                                                                                                                                      |

:::caution
Die meisten Unraid-Benutzer sollten Unterstützungs-vdevs/Subpools vermeiden, es sei denn, Sie haben spezifische und gut verstandene Anforderungen. Sie sind für spezialisierte Arbeitslasten ausgelegt und können bei missbräuchlicher Verwendung Komplexität oder Risiko einführen.
:::

---

## Kritische unterstützende vdev-Laufwerke beim Import nicht zugewiesen

When you import a %%ZFS|zfs%% pool into Unraid, you need to assign every drive from your original pool, including those used for support vdevs, to the pool slots. Unraid will automatically recognize each drive’s role (data, log, cache, special, or dedup) once the %%array|array%% starts. You don’t need to specify which drive serves what purpose manually.

Wenn Sie vergessen, ein Laufwerk, das Teil eines unterstützenden vdev war, beim Import einzubeziehen, hängt das Ergebnis von der Funktion des vdev ab:

| vdev-Typ                     | Wenn das Laufwerk beim Import fehlt                                        | Ergebnis                                                                                                                                                     |
| ---------------------------- | -------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Spezial-vdev oder Dedup vdev | Pool wird nicht importiert oder ist unbenutzbar                            | These vdevs store critical metadata or deduplication tables. Without them, %%ZFS\|zfs%% cannot safely mount the pool.                                        |
| Log (SLOG) vdev              | Pool wird importiert, aber die Synchronisierungs-Schreibleistung nimmt ab. | Der Pool bleibt zugänglich, aber Sie könnten eine langsamere Leistung für Arbeitslasten bemerken, die auf Synchronisierungs-Schreibvorgänge angewiesen sind. |
| Cache (L2ARC) vdev           | Pool wird importiert, aber der Lese-Cache geht verloren                    | Der Pool funktioniert normal, aber Sie verlieren die Leistungssteigerung durch den L2ARC-Cache. Es gehen keine Daten verloren.                               |

:::tip
Weisen Sie beim Importieren in Unraid immer alle physischen Laufwerke aus Ihrem ursprünglichen %%ZFS|zfs%%-Pool zu, einschließlich aller Unterstützungs-vdevs. Dies gewährleistet eine reibungslose Erkennung und Integration. Für neue in Unraid erstellte Pools sind Unterstützungs-vdevs optional und für die meisten Benutzer in der Regel nicht erforderlich.
:::

---

## Speicher erweitern

%%ZFS|zfs%% ist mächtig, aber es ist wichtig zu verstehen, wie seine Speichererweiterung funktioniert - besonders wenn Sie zukünftiges Wachstum planen.

Historisch gesehen haben %%ZFS|zfs%%-vdevs eine feste Breite. Sie können kein Laufwerk zu einem bestehenden RAIDZ-vdev hinzufügen, um es größer zu machen.

Möglichkeiten zur Erweiterung Ihres Pools umfassen:

- **Hinzufügen eines neuen vdevs:** Erweitern Sie Ihren Pool durch Hinzufügen eines neuen vdevs (wie einer neuen Spiegelung oder einer RAIDZ-Gruppe). Dies erhöht die Kapazität, aber Sie müssen Laufwerke in Sätzen hinzufügen, die der Konfiguration des vdevs entsprechen.
- **Ersetzen von Laufwerken durch größere:** Tauschen Sie jedes Laufwerk in einem vdev nacheinander gegen eine größere Festplatte. Siehe [Laufwerkserweiterung](../../using-unraid-to/manage-storage/array-configuration.mdx#replacing-faileddisabled-disks) für detaillierte Verfahren. Nachdem alle Laufwerke ersetzt und der Pool aufgelöst wurden, erhöht sich die Kapazität des vdevs.
- **Erstellen eines neuen Pools:** Das Starten eines neuen %%ZFS|zfs%% Pools hält Dinge für verschiedene Datentypen oder Arbeitslasten organisiert und unabhängig.

:::tip[Planning ahead]
Bevor Sie Ihren Pool aufbauen, überlegen Sie, wie viel Speicher Sie benötigen werden - nicht nur heute, sondern auch in der Zukunft. %%ZFS|zfs%% belohnt gutes Planen, insbesondere wenn Sie störende Erweiterungen später vermeiden möchten.
:::

---

## Die Verwendung von ZFS-Pools auf einem vorhandenen Unraid-Server

Wenn Sie ein traditionelles Unraid %%array|array%% laufen haben und %%ZFS|zfs%% Pools hinzufügen möchten, finden Sie hier einige effektive Möglichkeiten, sie zu integrieren:

| Anwendungsfall                                         | Beschreibung                                                                                                                                                                                       | Details / Beispiele                                                                                                                  |
| ------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| Schneller SSD/NVMe-Pool für App-Daten & Docker         | Store the appdata share for fast, responsive containers and databases. This supports %%snapshot\|snapshot%%s for easy rollbacks and can also host %%VM\|vm%%s for high I/O.                        | Viele Benutzer wählen einen 2-Laufwerk-%%ZFS\|zfs%%-Mirror für diesen Zweck. Es ist einfach zu erweitern und bietet starke Leistung. |
| ZFS-Pool für wichtige Daten                            | Use a %%ZFS\|zfs%% mirror or RAIDZ2 pool for irreplaceable files like photos, tax records, and %%user share\|user-share%% data. %%ZFS\|zfs%% checks for corruption and self-heals with redundancy. | Dieses Setup schützt kritische Daten mit automatischen Integritätsüberprüfungen und Selbstheilungsmöglichkeiten.                     |
| Tägliches Backup oder Replikationsziel                 | Use a %%ZFS\|zfs%% disk (even within the Unraid %%array\|array%%) as a replication target. You can replicate other pools locally or from another Unraid server.                                    | Nutzen Sie `zfs send/receive` oder Tools wie Syncoid für schnelle und zuverlässige Backups und Wiederherstellungen.                  |
| %%Snapshot\|snapshot%%-basierte Wiederherstellungspool | Keep point-in-time %%snapshot\|snapshot%%s of critical data or containers. %%snapshot\|snapshot%%s can be auto-scheduled and are space-efficient.                                                  | Diese Funktion ermöglicht eine schnelle Wiederherstellung nach versehentlichen Löschungen oder Fehleinstellungen.                    |

## Vermeidung häufiger ZFS-Fehler

%%ZFS|zfs%% ist ein leistungsstarkes Dateisystem, jedoch gibt es einige häufige Fallstricke, die seine Vorteile untergraben können. Es ist wichtig, die folgenden Punkte zu beachten, bevor Sie Ihren Pool konfigurieren, um eine reibungslosere Erfahrung zu gewährleisten:

- **Laufwerksgrößen-Mismatch in RAIDZ:** %%ZFS|zfs%% behandelt alle Festplatten in einem RAIDZ-vdev als die Größe der kleinsten. Um die beste Effizienz zu gewährleisten, verwenden Sie immer gleich große Laufwerke innerhalb jedes vdevs.

- **Erweiterung von RAIDZ-vdevs über das %%WebGUI|web-gui%%:** Während Unraid Version 7.1.x und neuer die Erweiterung von RAIDZ über die Befehlszeile unterstützt, ist diese Funktion im %%WebGUI|web-gui%% noch nicht verfügbar. Zurzeit erweitern Sie über die CLI oder fügen neue vdevs über die GUI hinzu.

- **%%ZFS|zfs%% disk vs. full zpool:** A single %%ZFS|zfs%%-formatted disk in the Unraid %%array|array%% does not offer the redundancy or features of a dedicated %%ZFS|zfs%% pool. To leverage advanced functionality, use standalone pools.

- **Deduplikation ohne ausreichenden RAM:** Deduplikation erfordert beträchtlichen Speicher, und die Aktivierung ohne ausreichenden RAM kann die Leistung erheblich beeinträchtigen. Aktivieren Sie die Deduplikation nur, wenn Sie die Anforderungen vollständig verstehen.

- **Vdev-Redundanz ist lokal:** Die Redundanz in %%ZFS|zfs%% ist lokal für jedes vdev und nicht über den Pool verteilt. Stellen Sie sicher, dass Sie Ihre vdev-Layout so planen, dass das gewünschte Maß an Widerstandsfähigkeit erreicht wird.
