---
sidebar_position: 2
sidebar_label: Array configuration
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import AddDataDiskParityProtected from './partials/add-data-disk-parity-protected.mdx';
import AddDataDiskNoParity from './partials/add-data-disk-no-parity.mdx';
import ParitySwapWhat from './partials/parity-swap-what.mdx';
import ParitySwapWhen from './partials/parity-swap-when.mdx';
import RemoveDataDiskStandard from './partials/remove-data-disk-standard.mdx';
import RemoveDataDiskParityPreserve from './partials/remove-data-disk-parity-preserve.mdx';
import ArrayCheckParity from './partials/array-check-parity.mdx';
import ArrayCheckRead from './partials/array-check-read.mdx';
import TroubleshootMissingDisks from './partials/troubleshoot-missing-disks.mdx';
import TroubleshootDeviceLimit from './partials/troubleshoot-device-limit.mdx';
import TroubleshootLicenseIssues from './partials/troubleshoot-license-issues.mdx';
import TroubleshootKeyServer from './partials/troubleshoot-key-server.mdx';
import TroubleshootWithdrawnRelease from './partials/troubleshoot-withdrawn-release.mdx';

# Array configuration

Unraid's storage system combines flexibility with data protection through its %%array|array%% and %%cache|cache%% architecture. The %%array|array%% manages your primary storage with optional %%parity|parity%% protection, while cache pools accelerate performance.

Below are some important array configuration principles:

<details>
  <summary><strong>å§‹ç»ˆä½¿ç”¨æœ€å¤§çš„é©±åŠ¨å™¨ç”¨äºæ ¡éªŒã€‚</strong></summary>

  å½“æ‚¨ç¨åå‘%%array|array%%ä¸­æ·»åŠ æ›´å¤šç£ç›˜æ—¶ï¼Œè¯·è®°ä½ï¼Œæ•°æ®ç£ç›˜çš„å¤§å°ä¸èƒ½è¶…è¿‡æ‚¨çš„%%parity disks|parity-drives%%ã€‚ä¸€å¼€å§‹è´­ä¹°æœ€å¤§çš„ç¡¬ç›˜ç”¨äº%%parity disks|parity-drives%%æ˜¯ä¸ªä¸é”™çš„ä¸»æ„ã€‚è¿™æ ·ï¼Œå½“æ‚¨åç»­æ‰©å±•æ—¶ï¼Œä¸ä¼šå—åˆ°è¾ƒå°å­˜å‚¨å®¹é‡çš„é™åˆ¶ã€‚

  å¦‚æœæ‚¨ä½¿ç”¨ä¸¤ä¸ª%%parity disks|parity-drives%%ï¼Œå®ƒä»¬å¯ä»¥æ˜¯ä¸åŒå¤§å°ã€‚ä½†æ˜¯ï¼Œè¯·è®°ä½ï¼Œ%%array|array%%ä¸­æ²¡æœ‰ä»»ä½•ç£ç›˜å¯ä»¥å¤§äºæ‚¨æ‰€æ‹¥æœ‰çš„æœ€å°%%parity disks|parity-drives%%ã€‚
</details>

<details>
  <summary><strong>ä¸è¦åœ¨é˜µåˆ—ä¸­ä½¿ç”¨SSD - å°†å®ƒä»¬ç”¨äºç¼“å­˜æ± æˆ–æœªåˆ†é…è®¾å¤‡ã€‚</strong></summary>

  Unraid does not support TRIM or Discard operations for SSDs in the main array. Over time, this will cause SSD performance to degrade if they are used as array members. For best results, use SSDs in %%cache pools|cache-pool%% or as unassigned devices, where these features are supported and long-term performance is maintained. Most modern SSDs, including NVMe, work well in these roles.
</details>

<details>
  <summary><strong>ä½¿ç”¨ç¼“å­˜æé«˜é˜µåˆ—å†™å…¥æ€§èƒ½ã€‚</strong></summary>

  æ•°æ®ä¸æ˜¯ç›´æ¥å†™å…¥ä¸»å­˜å‚¨ï¼Œè€Œæ˜¯é¦–å…ˆå‘é€åˆ°ä¸“ç”¨ç£ç›˜æˆ–ç£ç›˜ç»„ã€‚æ­¤æ•°æ®é€šå¸¸åœ¨å‡Œæ™¨3:40å®‰æ’æ—¶é—´è½¬ç§»åˆ°ä¸»å­˜å‚¨ã€‚ä¼Ÿå¤§çš„äº‹æƒ…æ˜¯ï¼Œä¿å­˜åˆ°%%cache|cache%%çš„æ•°æ®ä»ç„¶é€šè¿‡%%user shares|user-share%%æ˜¾ç¤ºå‡ºæ¥ï¼Œå› æ­¤æ‚¨ä¸éœ€è¦æ›´æ”¹è®¿é—®æ–‡ä»¶çš„æ–¹å¼ã€‚
</details>

<details>
  <summary><strong>åˆ›å»ºç¼“å­˜æ± æœ‰åŠ©äºä¿æŠ¤ç¼“å­˜æ•°æ®çš„å®‰å…¨ã€‚</strong></summary>

  ä»…ä½¿ç”¨ä¸€ä¸ªç¼“å­˜è®¾å¤‡ä¼šä½¿æ‚¨çš„ç¼“å­˜æ•°æ®åœ¨è½¬ç§»åˆ°ä¸»é˜µåˆ—ä¹‹å‰é¢ä¸´é£é™©ã€‚ä¸ºäº†ç¡®ä¿æ‚¨çš„æ•°æ®å§‹ç»ˆå—åˆ°ä¿æŠ¤ï¼Œä½¿ç”¨å¤šä¸ªè®¾å¤‡é…ç½®ä¸º%%cache pool|cache-pool%%ã€‚è¿™ç§è®¾ç½®ä¸ºç¼“å­˜æ•°æ®æä¾›å†—ä½™ï¼Œé™ä½ç”±äºç¼“å­˜è®¾å¤‡æ•…éšœå¯¼è‡´æ•°æ®ä¸¢å¤±çš„å¯èƒ½æ€§ã€‚
</details>

<details>
  <summary><strong>SSDç¼“å­˜è®¾å¤‡éå¸¸é€‚åˆåº”ç”¨ç¨‹åºå’Œè™šæ‹Ÿæœºã€‚</strong></summary>

  ä½¿ç”¨SSDå¯ä»¥ä½¿åº”ç”¨ç¨‹åºå’Œè™šæ‹Ÿæœºï¼ˆVMï¼‰è¿è¡Œæ›´å¿«ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥æ›´å¿«åœ°è®¿é—®æ•°æ®ã€‚SSDåœ¨%%cache pool|cache-pool%%ä¸­è¡¨ç°è‰¯å¥½ï¼Œä¸ºæ‚¨æä¾›é€Ÿåº¦ã€æ•ˆç‡å’Œæ•°æ®å®‰å…¨çš„å‡ºè‰²ç»„åˆã€‚
</details>

<details>
  <summary><strong>åŠ å¯†é»˜è®¤å…³é—­ã€‚</strong></summary>

  å¦‚æœæ‚¨æƒ³åœ¨ç³»ç»Ÿä¸Šä½¿ç”¨åŠ å¯†ï¼Œå¿…é¡»ä½¿ç”¨åŠ å¯†æ–‡ä»¶ç³»ç»Ÿç±»å‹é‡æ–°æ ¼å¼åŒ–ç£ç›˜ - è¿™ä¸ªè¿‡ç¨‹ä¼šæ“¦é™¤é©±åŠ¨å™¨ä¸Šçš„æ‰€æœ‰ç°æœ‰æ•°æ®ã€‚åœ¨å¯ç”¨åŠ å¯†ä¹‹å‰ï¼Œå°†æ•°æ®ç§»å‡ºç£ç›˜ï¼Œå°†æ–‡ä»¶ç³»ç»Ÿæ›´æ”¹ä¸ºåŠ å¯†é€‰é¡¹ï¼Œæ ¼å¼åŒ–ç£ç›˜ï¼Œç„¶åå°†æ•°æ®ç§»å›ã€‚è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[å¦‚ä½•åœ¨Unraidä¸­åŠ å¯†é©±åŠ¨å™¨](../../system-administration/secure-your-server/securing-your-data.mdx#how-to-encrypt-a-drive-in-unraid)ã€‚

  è¯·è®°ä½ï¼Œä½¿ç”¨åŠ å¯†ä¼šå¯¼è‡´æ•°æ®æ¢å¤éš¾åº¦å¢åŠ ï¼Œå› æ­¤ä»…åœ¨æ‚¨çœŸæ­£éœ€è¦æ—¶æ‰ä½¿ç”¨å®ƒã€‚
</details>

:::info[Disk Recognition and Port Flexibility]
Unraid identifies disks based on their serial numbers and sizes, not the specific SATA ports they're connected to. This means you can switch drives between different SATA ports without affecting their assignments in Unraid. This feature is particularly useful for troubleshooting hardware problems, like finding a faulty port or replacing unreliable power or SATA cables.
:::

:::caution
Your array will not start if you assign or attach more devices than your license key allows.
:::

## Start/Stop the array

When your system starts up, it usually powers up the array of disks automatically. However, if you've recently changed the disk setup, such as adding a new disk, the array will remain off to allow you to check your configuration.

:::caution
Keep in mind that you'll need to stop the array first to make any adjustments. Stopping it will fully stop all Docker containers and network shares, shut down or hibernate VMs, and your storage devices will be unmounted, making your data and applications inaccessible until you restart the array.
:::

To start or stop the array:

1. Click on the **Main** tab.
2. Navigate to the **Array Operation** section.
3. Click **Start** or **Stop**. You may need to check the box that says "Yes, I want to do this" before proceeding.

---

## Array operations

Unraid provides several maintenance and configuration options for your storage array. Key operations include:

import DocCardList from '@theme/DocCardList';

<DocCardList
  items={[
  { type: 'link', href: '#adding-disks', label: 'æ·»åŠ ç£ç›˜', description: 'æ‰©å±•å­˜å‚¨å®¹é‡' },
  { type: 'link', href: '#replacing-disks', label: 'æ›¿æ¢ç£ç›˜', description: 'å‡çº§æˆ–æ›´æ¢æ•…éšœé©±åŠ¨å™¨' },
  { type: 'link', href: '#removing-disks', label: 'ç§»é™¤ç£ç›˜', description: 'é€€å½¹æˆ–ç¼©å°é˜µåˆ—è§„æ¨¡' },
  { type: 'link', href: '#checking-array-devices', label: 'æ£€æŸ¥é˜µåˆ—è®¾å¤‡', description: 'ç›‘æ§SMARTæ•°æ®å’Œè¯Šæ–­' },
  { type: 'link', href: '#spinning-disks-down-or-up', label: 'è°ƒæ•´ç£ç›˜æ—‹è½¬', description: 'ç®¡ç†ç£ç›˜æ—‹è½¬å¯åœ' },
  { type: 'link', href: '#reset-the-array-configuration', label: 'é‡ç½®é˜µåˆ—é…ç½®', description: 'é‡å»ºé˜µåˆ—ç»“æ„' }
  ]}
/>

---

### Adding disks

#### Setting up new disks

1. Go to ***Main â†’ Array Devices*** in the interface.
2. Pick the slot where you want to add the disk and select the disk from the dropdown list.
3. By default, new array drives will be formatted with %%XFS|xfs%%. If you want to use %%ZFS|zfs%% or %%BTRFS|btrfs%% instead, select your preferred file system from the drop-down menu.

:::tip[Hot-Swap Feature]
If you're using modern Unraid-compatible hardware, you can change disks without shutting down your server. This feature, known as hot-swap, has been available in LimeTech servers since the beginning.
:::

#### Clear vs. Pre-Clear

Unraid requires disks to be in a cleared state - completely filled with zeros and marked with a special signature - before adding them to a parity-protected array. This process ensures parity integrity and keeps the array online during disk preparation.

Clearance is mandatory when adding a data disk to a %%parity|parity%%-protected array. If you are adding a %%parity disk|parity-drives%% or working with an array that does not use %%parity|parity%%, clearance is not required.

The built-in clear operation writes zeros to the disk in the background, allowing the array to remain available. Once the process is complete, the disk must be formatted before use. This method is efficient, requires no third-party tools, and is ideal for quick expansions.

For a more thorough approach, the pre-clear operation â€“ available through plugins like [Unassigned Devices Preclear](https://unraid.net/community/apps?q=unassigned+devices#r:~:text=enable%20destructive%20mode.-,Unassigned%20Devices%20Preclear,-dlandon) â€“ performs a pre-read to check for bad sectors, zeros the disk, and then verifies integrity with a post-read. This extra step helps detect early drive failures but takes significantly longer and requires manual plugin installation.

**Rule of thumb:** Use the built-in clear operation for fast additions to your array, or choose pre-clear if you want extensive testing of disk health before putting a drive into service.

<h4>Clear vs. Pre-Clear Comparison</h4>

<div style={{ margin: 'auto', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  |          | æ¸…é™¤       | é¢„æ¸…é™¤         |
  | -------- | -------- | ----------- |
  | **ç›®çš„**   | ç¡®ä¿åŸºæœ¬å…¼å®¹æ€§  | æµ‹è¯•é©±åŠ¨å™¨å¹¶å‡†å¤‡ä½¿ç”¨  |
  | **é€Ÿåº¦**   | å¤„ç†å¿«é€Ÿ     | è¿‡ç¨‹ååˆ†ç¼“æ…¢      |
  | **é˜µåˆ—å½±å“** | åœ¨åå°è¿è¡Œ    | éœ€è¦å°†ç£ç›˜ä»ä½¿ç”¨ä¸­ç§»é™¤ |
  | **æœ€ä½³ç”¨é€”** | éå¸¸é€‚åˆå¿«é€Ÿæ‰©å±• | é€‚åˆæ£€æŸ¥æ–°é©±åŠ¨å™¨    |
</div>

**Clear** quickly prepares a disk for use, making it compatible with your system and allowing you to add storage in just a few hours.

**Pre-Clear** takes longer but provides a thorough test, ensuring a new disk is reliable before it becomes part of your array.

:::caution[Critical Note]
Avoid formatting a pre-cleared disk before including it in the array, as this removes the clearance signature.
:::

#### Adding data disks

Adding data disks is a great way to increase your Unraid array's storage space. By adding more disks, you can keep more files, applications, and backups, while still protecting your data.

:::important[Important Note:]
When adding a new data disk, it must be the same size or smaller than your current %%parity disks|parity-drives%%. If you want to use a larger disk, you'll need to replace the %%parity disks|parity-drives%% first with the larger one, then use the old %%parity disks|parity-drives%% as a data disk.
:::

<details>
  <summary><strong>å¦‚ä½•æ·»åŠ æ•°æ®ç›˜</strong></summary>

  ```mdx-code-block

  <Tabs>
    <TabItem value="standard" label="Standard addition (Parity-protected)" default>
      <AddDataDiskParityProtected />
    </TabItem>

    <TabItem value="no-parity" label="Addition without parity">
      <AddDataDiskNoParity />
    </TabItem>
  </Tabs>
  ```
</details>

#### Adding parity disks

%%Parity disks|parity-drives%% are a helpful feature that provide an extra layer of protection for your data. They allow your storage system to recover information if a hard drive fails. While using %%parity disks|parity-drives%% is optional, it's highly recommended to keep your data safe.

:::important\[Requirements]

- **Single Parity:** The disk must be at least the same size as your largest data drive.
- **åŒParityï¼š** ä¸¤ä¸ª%%parity disks|parity-drives%%çš„å¤§å°ä¹Ÿå¿…é¡»ä¸å°äºæ‚¨æœ€å¤§çš„ä¸€ä¸ªæ•°æ®ç£ç›˜ï¼Œä½†å½¼æ­¤ä¹‹é—´å¯ä»¥æœ‰ä¸åŒçš„å¤§å°ã€‚

Adding a %%parity disk|parity-drives%% is similar to adding a data disk, but there's one important step to keep in mind:

1. After you select the %%parity disk|parity-drives%% and start your storage array, a process called **parity calculation** begins.
2. While this process runs, you can still access your files. However, the system might run a bit slower because it's working to calculate the parity.

<details>
  <summary><strong>æ·±å…¥äº†è§£ï¼šä»€ä¹ˆæ˜¯å¥‡å¶æ ¡éªŒä»¥åŠå®ƒä¸ºä½•é‡è¦ï¼Ÿ</strong> â€”â€” ç‚¹å‡»å±•å¼€/æ”¶èµ·</summary>

  Unraid ä¸­çš„ %%parity|parity%% é€šè¿‡%%å¥‡å¶æ ¡éªŒç›˜|parity-drives%%çš„ä½¿ç”¨ä¿æŠ¤æ‚¨çš„æ•°æ®ï¼Œç¡®ä¿æ‚¨å¯ä»¥ä»å­˜å‚¨å¤±è´¥ä¸­æ¢å¤ã€‚ä»»ä½•ä¸€ä¸ªä¸¢å¤±çš„ç£ç›˜éƒ½å¯ä»¥é€šè¿‡æ•´åˆå…¶ä»–æ•°æ®ç›˜çš„ä¿¡æ¯å’Œ %%parity|parity%% æ•°æ®æ¥é‡å»ºã€‚

  Unraid ä¾èµ–äºå®æ—¶å¥‡å¶æ ¡éªŒçš„ä¸¤ä¸ªä¸»è¦ç›®çš„ï¼š

  - Rebuilding data when a drive fails
  - Correcting errors when a bad sector is found

  æ­¤åŠŸèƒ½å…è®¸æ‚¨ä¿æŒæ•°æ®å®‰å…¨ï¼Œå³ä½¿é©±åŠ¨å™¨æœ€ç»ˆä¼šéšç€æ—¶é—´çš„æ¨ç§»è€Œå¤±æ•ˆã€‚
</details>

<details>
  <summary><strong>æ·±å…¥äº†è§£ï¼šUnraid å¥‡å¶æ ¡éªŒå¦‚ä½•å·¥ä½œï¼Ÿ</strong> â€”â€” ç‚¹å‡»å±•å¼€/æ”¶èµ·</summary>

  Unraid works with a special bit called the *parity bit*, which is stored for each bit position across all data disks and is managed by a dedicated %%parity disk|parity-drives%%. The %%parity|parity%% is calculated such that the total number of bits in each position across all disks (including the %%parity disk|parity-drives%%) is always an even number, a process known as even parity.

  Unraid ä¾èµ–äºå®æ—¶å¥‡å¶æ ¡éªŒçš„ä¸¤ä¸ªä¸»è¦ç›®çš„ï¼š

  - Unraid uses the XOR (exclusive OR) operation for this calculation.
  - For example, if you have four drives, and their 57th bits are 1, 1, 1, 1, the parity bit for that position will be 0 (because 1 + 1 + 1 + 1 + 0 = even).
  - However, if the 57th bits are 1, 0, 0, 0, the %%parity|parity%% for that position will be 1 (to ensure the total remains even).

  åœ¨æ·»åŠ æ–°ç£ç›˜æ—¶ï¼ŒUnraid é¦–å…ˆé€šè¿‡å†™å…¥é›¶æ¥æ¸…é™¤å®ƒã€‚è¿™å…è®¸å¿«é€Ÿçº³å…¥ä¿æŠ¤é˜µåˆ—ï¼Œå› ä¸ºå†™é›¶ä¸ä¼šå¹²æ‰°å½“å‰çš„å¥‡å¶æ ¡éªŒè®¡ç®—ã€‚
</details>

<details>
  <summary><strong>In-depth: How does Unraid parity work?</strong> - Click to expand/collapse</summary>

  Unraid works with a special bit called the *parity bit*, which is stored for each bit position across all data disks and is managed by a dedicated %%parity disk|parity-drives%%. The %%parity|parity%% is calculated such that the total number of bits in each position across all disks (including the %%parity disk|parity-drives%%) is always an even number, a process known as even parity.

  - It reads all remaining drives, including the %%parity disk|parity-drives%%.
  - It applies even %%parity|parity%% to solve for the missing data.

  ä¾‹å¦‚ï¼Œå¦‚æœé©±åŠ¨å™¨2å‡ºç°æ•…éšœï¼š

  - If the related bits are 1, 1, 1 (in addition to the %%parity|parity%%), Unraid calculates: 1 + x + 1 + 1 + 0 = even. Here, x must be 1 to maintain an even total.
  - If the bits show 1, x, 0, 0, 1 = even, then x will equal 0.

  æ­¤ %%parity|parity%% åŠŸèƒ½å…è®¸ Unraid â€œæ¨¡æ‹Ÿâ€ä¸¢å¤±çš„ç£ç›˜ã€‚æ‚¨å¯ä»¥ç»§ç»­åƒç£ç›˜ä»ç„¶æ­£å¸¸å·¥ä½œä¸€æ ·ä½¿ç”¨é˜µåˆ—ã€‚ä¸€æ—¦æ‚¨åœ¨å¤±è´¥ä½ç½®å®‰è£…æ–°ç£ç›˜ï¼ŒUnraid å°†æ ¹æ®å½“å‰ %%parity|parity%% å’Œå…¶ä»–ç£ç›˜çš„çŠ¶æ€é‡å»ºæ‰€æœ‰ä¸¢å¤±çš„æ•°æ®ã€‚

  ä¸ºäº†ç¡®ä¿æŒç»­çš„ä¿æŠ¤å’Œæœ‰æ•ˆçš„æ¢å¤ï¼Œå®šæœŸè¿è¡Œ%%parity checks|parity-check%%æ˜¯å¾ˆé‡è¦çš„ã€‚
</details>

<details>
  <summary><strong>æ·±å…¥äº†è§£ï¼šå¦‚ä½•ä½¿ç”¨æ ¡éªŒé‡å»ºæ•°æ®ï¼Ÿ</strong> - ç‚¹å‡»å±•å¼€/æŠ˜å </summary>

  Your %%parity disk|parity-drives%% must be **equal to or larger than your largest data disk**. For instance:

  - If your largest data disk is 10TB, your %%parity disk|parity-drives%% should be at least 10TB.
  - You can use various other data disk sizes freely, as long as none exceeds the size of the %%parity disk|parity-drives%%.
</details>

<details>
  <summary><strong>æˆ‘çš„æ ¡éªŒç£ç›˜éœ€è¦å¤šå¤§ï¼Ÿ</strong> - ç‚¹å‡»å±•å¼€/æŠ˜å </summary>

  Writing to a %%parity|parity%%-protected array involves four disk operations for each write: reading data, reading %%parity|parity%%, writing data, and writing %%parity|parity%%. This process requires a full rotation from each affected drive, so the overall write speed is limited by the slowest drive involved in the operation.

  æ·»åŠ æ›´å¿«çš„ %%parity disk|parity-drives%% ä¸ä¸€å®šä¼šæé«˜å†™å…¥é€Ÿåº¦ï¼Œé™¤éæ‚¨åŒæ—¶å‘å¤šä¸ªæ…¢é€Ÿæ•°æ®ç›˜å†™å…¥ï¼Œè¿™å…è®¸ %%parity disk|parity-drives%% æ‰¿æ‹…è´Ÿè½½ã€‚é€šå¸¸ï¼Œå†™å…¥é€Ÿåº¦å—é™äºæ­£åœ¨å†™å…¥çš„æœ€æ…¢æ•°æ®ç›˜ã€‚
</details>

<details>
  <summary><strong>æ·±å…¥äº†è§£ï¼šæ ¡éªŒå¦‚ä½•å½±å“å†™å…¥æ€§èƒ½ï¼Ÿ</strong> - ç‚¹å‡»å±•å¼€/æŠ˜å </summary>

  Dual %%parity|parity%% enables recovery from **two simultaneous disk failures**. In Unraid, the second %%parity disk|parity-drives%% doesn't simply mirror the first. Instead:

  - **Parity 1:** Employs standard XOR (even) %%parity|parity%% calculations.
  - **Parity 2:** Utilizes a more complex algorithm (Galois field, rather than Reed-Solomon as in traditional %%RAID 6|raid6%%), allowing Unraid to rebuild from any two missing disks at the same time. This feature is significant for larger arrays, where the risk of multiple failures increases. Dual %%parity|parity%% significantly boosts resilience without the added overhead of mirrored redundancy.
</details>

:::caution\[Remember]
When setting up a new data storage system, add your data disks **first**, making sure they all use a compatible file system. **After** placing your data disks, you can add a %%parity disk|parity-drives%% to protect against drive failures.

ä¸€æ—¦æ‚¨çš„ %%parity disk|parity-drives%% æ·»åŠ åï¼Œè¯·è®°ä½ï¼Œæ‚¨è¦æ·»åŠ åˆ°é˜µåˆ—ä¸­çš„ä»»ä½•æ–°ç£ç›˜å¿…é¡»åœ¨æ•´åˆå‰æ¸…é›¶ã€‚è¿™æ˜¯ä¸ºäº†ç¡®ä¿ %%parity|parity%% ä»ç„¶æœ‰æ•ˆå¹¶ç»§ç»­ä¿æŠ¤æ‚¨çš„æ•°æ®ã€‚
:::

#### Upgrading parity disks

You can upgrade your %%parity disk|parity-drives%% device(s) to a larger one(s) to use larger-sized disks in the array or add an additional %%parity disk|parity-drives%%.

:::caution
If you're planning to take the following steps and only have one %%parity disk|parity-drives%%, keep these points in mind:

- Your data will be unprotected until the %%parity|parity%% rebuild is complete. If a data drive fails during this time, you could lose the information on that drive.
- å¦‚æœæ‚¨å·²ç»æœ‰ä¸€ä¸ªå­˜å‚¨ç›˜å¤±è´¥ï¼Œç»§ç»­è¿™äº›æ­¥éª¤å°†æ— æ³•é‡å»ºè¯¥ç£ç›˜ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥æ”¹ä¸ºéµå¾ª **Parity Swap** è¿‡ç¨‹ã€‚
  :::

To remove a parity drive:

1. **Stop the array:** Use the %%WebGUI|web-gui%% to stop the array.

:::tip
If your server supports hot-swap, you do not need to power down to change disks. You can safely skip steps 2 and 4.
:::

2. **Power down the server:** Turn off your server to safely make hardware changes.
3. **Install the new %%parity disk|parity-drives%%:** Place the new, larger %%parity disk|parity-drives%% into your server.
4. **Power up the server:** Turn the server back on.
5. **Assign the new disk:** Go to the parity slot in your settings and assign the new disk, replacing the old one.
6. **Start the array:** Use the %%WebGUI|web-gui%% to start the array again.

Once the array is back up, Unraid will start building %%parity|parity%% on the new disk. You can still access your data during this time, but keep in mind that it might be a bit slower until the process is done. Once the %%parity|parity%% build is complete, your data is protected again!

:::important[Important Tips]

- **Keep the old disk:** Don't remove the old %%parity disk|parity-drives%% until the new %%parity|parity%% build finishes. If a data disk fails during the upgrade, having the old disk might help you recover your data.

- **Dual parity users:** If you have two %%parity disks|parity-drives%%, upgrade one at a time for added safety.

- **Repurpose the old disk:** After the upgrade, you can use the old %%parity disk|parity-drives%% as a data disk if it still meets your storage needs.
  :::

---

### Replacing disks

You may need to replace disks in your array for two main reasons:

1. [**Capacity upgrade**](#upgrading-capacity): Your storage is nearly full, and you want to use larger disks.
2. [**Failure or retirement**](#replacing-faileddisabled-disks): A disk has failed or is no longer supported.

While the process for replacing disks is similar in both cases, be cautious, as there is a risk of data loss during the replacement. Parity devices help protect your data; one parity device can safeguard against a single disk failure, while two can protect against losing data if two disks fail. Always be aware of your protection level during disk replacements.

#### Upgrading capacity

When upgrading your data drive to a larger one, here are some points to keep in mind:

- **Unmountable disks:** Fix any unmountable disks before upgrading. An unmountable status won't be resolved during the rebuild.

- **Single parity risks:** If you have single parity, you're at risk of data loss if another drive fails during the upgrade. Seek advice in forums if this happens.

- **Dual parity protection:** With dual parity, you're safe from losing data if one drive fails while upgrading a single drive. You can also upgrade two drives at once, but note that this increases the risk since you won't have protection against another drive failing.

- **Backup the old disk:** Keep the original disk intact until the upgrade is confirmed successful. This provides a fallback option if anything goes wrong.

:::warning
Replacing drives always involves some risk. If another drive fails during the upgrade, especially with only single parity, you may experience data loss. Always check the health of your drives before beginning the process, and ensure that you keep the old drive intact until the upgrade is complete and your data is confirmed to be safe.
:::

To upgrade an existing data disk:

1. **Run a parity check:** First, ensure the integrity of your data by running a %%parity check|parity-check%%. Go to [***Tools â†’ Parity Check***](#checking-array-devices) and make sure there are **zero errors**. If parity isn't valid, rebuilding the disk will corrupt its file system.

2. **Stop the array:** Next, you'll want to stop the array. Navigate to ***Main â†’ Array Operation*** and select **Stop**.

3. **Unassign the target disk:** Once the array is stopped, find the disk you want to replace. Remove it from its slot in ***Main â†’ Array Devices***.

4. **Start the array:** Now, start the array again. Unraid will emulate the missing disk using the existing parity and data disks. You have two modes to choose from:
   - **%%Maintenance Mode|maintenance-mode%%:** This mode prevents any writes to the %%emulated disk|emulated-disk%%.
   - **Normal Mode:** If you need read/write access to the %%emulated disk|emulated-disk%%, select this option.

:::note
Starting the array in Normal Mode at this point is optional. You can use it to verify that the emulated disk mounts and the data looks correct before proceeding, but it is not required for the upgrade process.
:::

5. **Stop the array again:** The array should now show that the unassigned disk has failed. Stop the array once more.

6. **Assign the replacement disk:** Insert your new, larger disk into the vacant slot in the array.

7. **Start the array to rebuild:** Finally, start the array again. Unraid will now rebuild the contents of the %%emulated disk|emulated-disk%% onto the new disk. The file system will automatically adjust to take full advantage of the larger disk's capacity.

#### Replacing failed/disabled disks

<details>
  <summary><strong>ä»€ä¹ˆæ˜¯æ•…éšœ/ç¦ç”¨ç£ç›˜ï¼Ÿ</strong></summary>

  A failed or disabled disk is one that Unraid has stopped using for writing data, usually because it encountered a write error. Keep in mind these don't always mean the drive itself is broken; sometimes, it might be due to bad connections, power issues, or just a temporary glitch.

  ä¸€äº›æŒ‡ç¤ºåŒ…æ‹¬ï¼š

  <div class="text--center">
    ![Red "X" indicates write error](/img/Diskfailureindicator.png)
    <p class="caption-center">*This red "X" shows which disk needs replacement.*</p>
  </div>

  <br />

  <div class="text--center">
    ![Failure notification alert](/img/Diskfailurenotification.png)
    <p class="caption-center">*Keep an eye out for these alerts.*</p>
  </div>

  <br />

  <details>
    <summary><strong>ç‚¹å‡»æŸ¥çœ‹ä¸åŒå¥‡å¶æ ¡éªŒé…ç½®å¦‚ä½•å¤„ç†ç£ç›˜æ•…éšœ</strong></summary>

    | æ•…éšœåœºæ™¯ | æ— å¥‡å¶æ ¡éªŒ | å•ä¸€å¥‡å¶æ ¡éªŒ | åŒé‡å¥‡å¶æ ¡éªŒ |
    | ---- | ----- | ------ | ------ |

    \| **1ç£ç›˜æ•…éšœ** | æ•°æ®ä¸¢å¤± | å¯é‡å»º | å¯é‡å»º |
    \| **2ç£ç›˜æ•…éšœ** | æ•°æ®ä¸¢å¤± | æ•°æ®ä¸¢å¤± | å¯é‡å»º |

    :::tip[å®‰å…¨é‡å»ºæç¤º]

    - **å¯¹äºå•ä¸ªæ ¡éªŒï¼š** æ‚¨åªèƒ½ä¸€æ¬¡æ›¿æ¢ä¸€ä¸ªç£ç›˜ã€‚å¦‚æœåœ¨é‡å»ºæœŸé—´å¦ä¸€ä¸ªç£ç›˜å‡ºç°æ•…éšœï¼Œæ‚¨å¯èƒ½ä¼šä¸¢å¤±æ•°æ®ã€‚
    - **å¯¹äºåŒé‡æ ¡éªŒï¼š** æ‚¨å¯ä»¥åŒæ—¶æ›¿æ¢ä¸€åˆ°ä¸¤ä¸ªç£ç›˜ï¼Œä½†å¦‚æœè¶…è¿‡ä¸¤ä¸ªç£ç›˜å‡ºç°æ•…éšœï¼Œè¯·è°¨æ…å¤„ç†ã€‚
      :::

    :::é‡è¦
    å¦‚æœæ‚¨é‡åˆ°äº†**è¶…è¿‡æ ¡éªŒä¿æŠ¤èƒ½åŠ›çš„ç£ç›˜æŸå:**

    1. **ç«‹å³åœæ­¢æ‰€æœ‰å†™æ“ä½œ**ä»¥é˜²æ­¢è¿›ä¸€æ­¥çš„æ•°æ®ä¸¢å¤±ã€‚
    2. é€šè¿‡åœ¨[Unraid è®ºå›](https://forums.unraid.net/)å‘å¸–å¹¶é™„ä¸Šè¯Šæ–­ä¿¡æ¯å¯»æ±‚å¸®åŠ©ã€‚
    3. **åœ¨æ”¶åˆ°å»ºè®®ä¹‹å‰ä¸è¦å°è¯•é‡å»º** - é¦–å…ˆå…³æ³¨æ•°æ®çš„æŠ¢æ•‘ã€‚
       :::
  </details>
</details>

<details>
  <summary><strong>å¦‚ä½•è¯Šæ–­é—®é¢˜</strong></summary>

  è¦è¯Šæ–­é—®é¢˜ï¼Œè¯·ä»æ£€æŸ¥%%syslog|syslog%%å’Œ%%SMARTæŠ¥å‘Š|smart-report%%å¼€å§‹ï¼š

  - If the %%syslog|syslog%% shows that the drive has reset, there might be a problem with the connection or cables.
  - %%SMART reports|smart-report%% can help assess the drive's health, but the best way to check is by running a %%SMART|smart%% extended test. If it completes without errors, the drive is likely fine.
  - If you see %%CRC errors|crc-errors%%, it usually points to issues with the cabling. Keep an eye on these errors, as they accumulate over time and don't reset.

  :::tip
  è¦äº†è§£é©±åŠ¨å™¨é—®é¢˜ï¼Œ[å¯ç”¨é€šçŸ¥](../../getting-started/set-up-unraid/customize-unraid-settings.mdx#notification-settings)åœ¨Unraidä¸­ã€‚è¿™æ ·ï¼Œä¸€æ—¦å‡ºç°é—®é¢˜ï¼Œæ‚¨å°±ä¼šç«‹å³å¾—åˆ°è­¦æŠ¥ï¼Œä»è€Œé™ä½æ•°æ®é£é™©ã€‚
  :::
</details>

<details>
  <summary><strong>ä»€ä¹ˆæ˜¯æ¨¡æ‹Ÿï¼Ÿ</strong></summary>

  When a drive is disabled, Unraid will use its parity and other working drives to emulate the failed drive. This means your system continues to operate, and you can still access the data stored on the %%emulated drive|emulated-disk%%:

  - Unraid will stop writing to the physical drive, and any updates will be saved in parity and the emulation instead.
  - Before replacing the failed drive, you can check and recover data from the %%emulated drive|emulated-disk%%, which keeps the physical drive intact for potential recovery.
  - If you can't access the %%emulated drive|emulated-disk%%, repairing the file system is essential before any rebuild since fixing the file system is quicker and more effective than a rebuild.
</details>

<details>
  <summary><strong>ä»€ä¹ˆæ˜¯æ•…éšœ/ç¦ç”¨ç£ç›˜ï¼Ÿ</strong></summary>

  A failed or disabled disk is one that Unraid has stopped using for writing data, usually because it encountered a write error. Keep in mind these don't always mean the drive itself is broken; sometimes, it might be due to bad connections, power issues, or just a temporary glitch.

  è™½ç„¶ä¸æ˜¯å¼ºåˆ¶æ€§çš„ï¼Œè®¸å¤šç”¨æˆ·é€‰æ‹©é¢„æ¸…ç†æ–°é©±åŠ¨å™¨ä»¥æµ‹è¯•å®ƒä»¬å¹¶å¸®åŠ©é˜²æ­¢æ—©æœŸæ•…éšœã€‚æ‚¨å¯ä»¥ä½¿ç”¨Preclearæ’ä»¶ã€%%SMART|smart%%å»¶ä¼¸æµ‹è¯•æˆ–åˆ¶é€ å•†å·¥å…·æ¥æ‰§è¡Œæ­¤æ“ä½œã€‚

  :::å°å¿ƒ
  å¦‚æœæ‚¨è¯•å›¾ä½¿ç”¨ä¸å¯æŒ‚è½½çš„%%emulated drive|emulated-disk%%è¿›è¡Œé‡å»ºï¼Œæ–°é©±åŠ¨å™¨ä¹Ÿå°†æ— æ³•æŒ‚è½½ã€‚åœ¨å°è¯•é‡å»ºä¹‹å‰åŠ¡å¿…ä¿®å¤æ–‡ä»¶ç³»ç»Ÿã€‚
  :::
</details>

If a disk in your Unraid system has failed or is disabled, don't worry! You can replace it and recover your data. Just follow these simple steps. Remember, you need a new disk that is the same size or larger than the one you're replacing, but it can't be larger than your smallest %%parity disk|parity-drives%%.

:::important
Before you start, make sure to check for any disk errors or warnings. Unraid must be able to read all the remaining disks without any issues for the rebuild to work correctly. If another disk is failing, it could lead to data loss.
:::

To replace and rebuild a disk:

1. **Stop the array:**

   - Log in to the Unraid %%WebGUI|web-gui%% (the web interface).
   - Find the option to stop the array. This is necessary before you can change any disks.

:::tip
If your server supports hot-swap, you can skip the next step and just stop the array.
:::

2. **Power down your server** (only if **not** using hot-swap):
   - If your server doesn't support hot-swap, you'll need to shut it down completely.

3. **Replace the failed disk:**
   - Remove the old, failed disk from your server.
   - Insert the new disk. Just remember, it has to be at least the same size as the old disk but no bigger than your smallest %%parity disk|parity-drives%%.

4. **Power up the server** (if you powered it down):
   - Turn your server back on if you shut it down.

5. **Assign the new disk:**
   - Go back to the Unraid %%WebGUI|web-gui%%.
   - Find the slot for the failed disk and assign your new disk to that slot.

6. **Confirm your action:**
   - You'll see a confirmation box. Check the box that says **Yes, I want to do this** and confirm.

7. **(Optional) Choose %%Maintenance Mode|maintenance-mode%%:**
   - You can select %%Maintenance Mode|maintenance-mode%%, which can make the rebuild process faster. However, during this time, you won't be able to access the array at all.
   - If you choose %%Maintenance Mode|maintenance-mode%%, make sure to click **Sync** to start the rebuild.

8. **Start the rebuild:**
   - Click **Start** to begin the process. Unraid will copy your data from the %%emulated disk|emulated-disk%% to the new disk.
   - If your new disk is larger, Unraid will manage the extra space for you.

:::warning
If Unraid prompts you to format the new disk during the rebuild, **do not do it**. Formatting will wipe all data and make recovery impossible.
:::

<h4>What to expect during the rebuild</h4>

- The array will still be available to use during the rebuilding process (unless you're in %%Maintenance Mode|maintenance-mode%%), but it might run slower.
- Rebuilding can take several hours, depending on your disk sizes and system usage.
- The new disk will have the same file system as the original.
- If the old disk was unmountable due to file system issues, the new disk will also not be mountable. Please fix any file system issues before starting the rebuild.

:::note[Additional notes]

- The rebuild process won't change the file format of the disk; it simply restores its previous form.
- åœ¨æ‚¨å¼€å§‹é‡å»ºä¹‹å‰ï¼ŒåŠ¡å¿…æ£€æŸ¥æ¯ä¸ªç£ç›˜çš„å¥åº·çŠ¶å†µä»¥é¿å…æ½œåœ¨é—®é¢˜ã€‚
  :::

#### Parity swap

```mdx-code-block

<Tabs>
  <TabItem value="what" label="What is parity swap?">
    <ParitySwapWhat />
  </TabItem>

  <TabItem value="when" label="When to use parity swap?">
    <ParitySwapWhen />
  </TabItem>
</Tabs>
```

<details>
  <summary><strong>ç¤ºä¾‹åœºæ™¯</strong></summary>

  æ‚¨æœ‰ä¸€ä¸ª Unraid è®¾ç½®ï¼Œå…¶ä¸­æœ‰ä¸€ä¸ª**2TB æ ¡éªŒç›˜**å’Œä¸€ä¸ª**1TB æ•°æ®ç›˜**ï¼Œå¹¶å¸Œæœ›å°† 1TB ç£ç›˜æ¢æˆ**4TB ç£ç›˜**ã€‚

  é¦–å…ˆï¼Œå°†æ–°4TBé©±åŠ¨å™¨åˆ†é…ä¸ºæ ¡éªŒé©±åŠ¨å™¨ï¼Œä»¥æ›¿æ¢2TBé©±åŠ¨å™¨ã€‚ç„¶åå°†åŸå§‹çš„2TBé©±åŠ¨å™¨ç§»åŠ¨åˆ°æ•°æ®æ§½ï¼Œå¹¶å®Œå…¨ç§»é™¤1TBé©±åŠ¨å™¨ã€‚

  ç»è¿‡è¿™äº›æ›´æ”¹åï¼Œæ‚¨å°†æ‹¥æœ‰ä¸€ä¸ª4TBé©±åŠ¨å™¨ä½œä¸ºæ–°æ ¡éªŒï¼Œä»¥ç¡®ä¿å¯ä»¥æ·»åŠ æœªæ¥æœ€å¤§è‡³4TBçš„æ•°æ®é©±åŠ¨å™¨ã€‚2TBé©±åŠ¨å™¨å°†å­˜å‚¨ç°æœ‰æ•°æ®ï¼Œè€Œ1TBé©±åŠ¨å™¨å¯ä»¥é‡æ–°åˆ†é…ç”¨é€”ã€‚

  è¿™ç§äº¤æ¢ä¿æŒæ‚¨çš„æ•°æ®å®‰å…¨å¹¶ä¿æŠ¤æ‚¨çš„é˜µåˆ—ï¼Œå…è®¸å°†æ¥è¿›è¡Œå‡çº§ã€‚
</details>

:::important\[Prerequisites]

- Before starting, ensure the data drive you want to replace is disabled. If the drive has failed (shows a red indicator), it is already disabled. If the drive is healthy but you want to replace it, unassign the drive and start the array once without it to force Unraid to mark it as disabled.
- If your replacement data drive is not larger than your parity drive, use the standard [Replacing a Data Drive](#replacing-faileddisabled-disks) procedure instead.
- æ­¤è¿‡ç¨‹ä»…é€‚ç”¨äºå°† Unraid é˜µåˆ—ä¸­çš„æ•°æ®ç›˜æ›¿æ¢ä¸ºå¤§äºå½“å‰å¥‡å¶æ ¡éªŒç›˜çš„ç£ç›˜ã€‚å¦‚æœæ‚¨åªæ˜¯éœ€è¦å‡çº§å¥‡å¶æ ¡éªŒç›˜ï¼Œåªéœ€ç§»é™¤æ—§å¥‡å¶æ ¡éªŒç›˜ï¼Œæ·»åŠ æ–°ç›˜ï¼Œç„¶åå¯åŠ¨é˜µåˆ—ã€‚å¥‡å¶æ ¡éªŒå°†è‡ªåŠ¨é‡å»ºã€‚
  :::

:::warning\[Warnings]

- Always verify the health of all drives using %%SMART reports|smart-report%% before starting a %%parity swap|parity-swap%%. Attempting this procedure with another failing or unhealthy disk increases the risk of data loss.
- Preclear the new disk if possible. While not required, preclearing stress-tests the drive and reduces the risk of early failure.
- åœ¨å¼€å§‹ä¹‹å‰æ­£ç¡®è¯†åˆ«æ‰€æœ‰ç£ç›˜ã€‚æ³¨æ„å‹å·å’Œæ¯ä¸ªåºåˆ—å·çš„æœ€åå››ä¸ªå­—ç¬¦ï¼Œä»¥é¿å…åˆ†é…ä¸­çš„é”™è¯¯ã€‚
  :::

To carry out a parity swap:

:::note
If the drive to be replaced is already disabled (failed), you may not need to perform steps 1â€“4. If you have already installed the new replacement drive (for example, after preclearing), you can skip steps 5â€“8.
:::

1. **Stop the array** if it is running.
2. **Unassign the old data drive** if it is still assigned. If the drive was previously healthy, you may see error notifications for a missing drive - this is expected.
3. **Start the array.** If prompted, check the box confirming your action. The data drive should now show as "Not installed."
4. **Stop the array again.** At this point, the array treats the drive as failed.
5. **Power down the server.**

   :::tip
   å¦‚æœæ‚¨çš„ç³»ç»Ÿæ”¯æŒ**çƒ­æ’æ‹”**ï¼Œæ‚¨ä¸éœ€è¦æ–­ç”µå³å¯æ‹†è£…é©±åŠ¨å™¨ã€‚åªéœ€åœ¨è¿›è¡Œç¡¬ä»¶æ›´æ”¹å‰åœæ­¢é˜µåˆ—ã€‚
   :::

:::

6. *(Optional)* **Remove the old drive.** You may wish to keep it installed for testing or reassignment.
7. **Install the new drive.** Pre-clearing is strongly recommended, but formatting is not needed.
8. **Power on the server.**
9. **Stop the array** if it started automatically. If you see a message about retrying to unmount disk shares, disable Docker and/or VM services in Settings, reboot, and try again.
10. **Unassign the parity drive.**
11. **Assign the new drive to the parity slot.** You may receive error notifications - this is normal.
12. **Assign the old %%parity drive|parity-drives%% to the data slot** of the drive being replaced. Both the parity and replacement data drives should now display blue status indicators.
13. **Go to *Main â†’ Array Operation.*** You should see a **Copy** button and a message stating "Copy will copy the parity information to the new %%parity disk|parity-drives%%."
14. **Confirm and start the copy process.** Check the confirmation box and click **Copy**. The array will not be available during this operation.

- The copy process can take many hours, depending on disk size. When finished, the array will be stopped and ready for a data rebuild.

15. **Start the array to begin the data rebuild.**
    - Confirm your action if prompted. The array is now started, and data is reconstructed onto the new data drive.
    - You can use the array during the rebuild, but for best performance, limit usage.
    - The rebuild process will also take several hours.

:::warning
Never format a drive during this process. Formatting will erase all data and update parity, making recovery impossible.
:::

After completion, you will have a larger parity disk and a replaced data disk. Many users run a %%parity check|parity-check%% afterward for extra confidence, though this is optional.

---

### Removing disks

There may come a time when you want to remove a disk from your Unraid array. Whether you're looking to save on power, retire an old or unreliable drive, or repurpose hardware for a different use, the process is fairly straightforward.

#### Removing parity disks

If you find that you no longer need the level of %%parity|parity%% protection in your setup, you can remove a %%parity disk|parity-drives%% whenever you want.

To remove a %%parity drives|parity-drives%%:

1. **Stop the array:** Begin by accessing the %%WebGUI|web-gui%% and stopping the array.
2. **Unassign the %%parity drives|parity-drives%%:** Locate the %%parity drives|parity-drives%% slot and set it to "Unassigned."
3. **Start the array:** Finally, restart the array to commit the changes and successfully remove the %%parity drives|parity-drives%% from the configuration.

:::warning
Before you make any changes, please keep this in mind: If you already have any failed data drives in your array, removing a %%parity disk|parity-drives%% can decrease the number of failures Unraid can handle without risking data loss.

- With dual parity, you can recover from a single failed drive, but be aware that you won't be able to survive another failure during the rebuild process.
- å•å¥‡å¶æ ¡éªŒæ—¶ï¼Œæ‚¨å¤±å»æ‰€æœ‰å†—ä½™ï¼Œè¿™æ„å‘³ç€ä»»ä½•é¢å¤–çš„å­˜å‚¨æ•…éšœéƒ½å¯èƒ½å¯¼è‡´æ•°æ®ä¸¢å¤±ã€‚
  :::

#### Removing data disks

Removing a data disk is a straightforward process, but it's important to remember that you'll need to perform a %%parity|parity%% sync afterwards. Until this sync is complete, there's a risk of data loss if another disk fails.

You can choose from two methods to remove a data disk:

1. **Standard method** - Recommended for most users.
2. **Parity-preserve method** - Suitable for advanced users who want to maintain parity during the removal.

```mdx-code-block

<Tabs>
  <TabItem value="standard" label="Standard method" default>
    <RemoveDataDiskStandard />
  </TabItem>

  <TabItem value="parity-preserve" label="Parity-preserve method (Advanced)">
    <RemoveDataDiskParityPreserve />
  </TabItem>
</Tabs>
```

---

### Checking array devices

Regularly checking your Unraid array is crucial for maintaining data integrity and identifying potential issues before they result in data loss. You can initiate a check using the **Check** button under ***Array Operations***. Depending on your array's configuration, this button allows you to conduct either a %%parity check|parity-check%% or a %%read check|read-check%%.

<div style={{ margin: 'auto', maxWidth: '400px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![æ£€æŸ¥æŒ‰é’®å¯è®©æ‚¨è¿›è¡Œæ ¡éªŒå’Œè¯»å–æ£€æŸ¥](/img/Check_button.PNG)
</div>

For convenience, you can schedule these checks to run automatically at intervals that suit you by navigating to ***Settings â†’ Scheduler***. It's advisable to perform automated, non-correcting checks on a monthly or quarterly basis to ensure the ongoing health of your data.

#### Parity & Read checks

```mdx-code-block

<Tabs>
  <TabItem value="parity-check" label="Parity checks" default>
    <ArrayCheckParity />
  </TabItem>

  <TabItem value="read-check" label="Read checks">
    <ArrayCheckRead />
  </TabItem>
</Tabs>
```

#### Check history

Whenever the system performs a %%parity check|parity-check%% or a %%read check|read-check%%, it keeps a record of what happened. You can view these details easily by clicking the **History** button found under ***Array Operations*** in the interface.

For those who want to dive deeper, all these records are saved in a text file located in the `config` directory on your Unraid USB flash device.

---

### Spinning disks down or up

Unraid allows you to control the power states of your hard drives. You can easily %%spin them up or down|spin-state%%, and manage SSDs to be active or in standby. This helps save energy, extend the life of your drives, and reduce noise when the disks are not being used.

<h4>Why spin down or up?</h4>

- **Spin down:** If you have drives that aren't used often, spinning them down can save energy and help them last longer.
- **Spin up:** If you know you'll need files soon, spinning up the disks ahead of time can cut down wait times.

<h4>How to control spin states</h4>

You can control disk spin states through the **Main** tab in the %%WebGUI|web-gui%%:

1. **Go to the Main tab** and locate your array devices
2. **Find the spin control buttons** - each disk will show either:
   - Click the ğŸ”˜ button to **Spin Up** if the disk is currently spun down
   - Click the ğŸŸ¢ button to **Spin Down** if the disk is currently spinning
3. **Click the appropriate button** for the action you want:
   - Click **Spin Down** ğŸŸ¢ to power down an idle disk and save energy
   - Click **Spin Up** ğŸ”˜ to power up a disk that's currently spun down

Remember that if a disk is being accessed (like if you're opening a file), it will stay active and ignore any spin-down request.

When a disk is spun down, its temperature won't show in the %%WebGUI|web-gui%%. However, once any application or user accesses it, it will automatically spin up.

:::tip
Use the spin controls to save power and reduce wear on your drives. Remember that disks that are actively being used will stay on until all tasks are finished.
:::

---

### Reset the array configuration

Resetting your array configuration is an important step that should be undertaken carefully. This process is usually necessary when removing a disk, starting fresh with a new array layout, or fixing disk assignment issues. Please note that this action can impact data protection and parity, so ensure you only proceed when truly needed.

Common reasons to reset your array include:

- **Removing or replacing disks:** If you need to take out or swap out any disks in your array.
- **Starting anew:** When you're looking to create a brand new layout for your array.
- **Fixing disk assignment errors:** To correct any issues with how disks are currently assigned.
- **Recovering from configuration problems:** When facing challenges with your existing setup.

<div style={{ margin: 'auto', maxWidth: '650px', display: 'flex', flexDirection: 'column', alignItems: 'center' }}>
  ![é‡ç½®ç£ç›˜é…ç½®å¯ä»¥é€šè¿‡æ–°é…ç½®é¡µé¢å®Œæˆ](/img/Newconfig.png)
</div>

To reset your array configuration:

1. Go to the **Tools** page and click on **New Config**.
2. You can keep some existing disk assignments if you only wish to make minor adjustments. This can save time and minimize the chance of errors.
3. Confirm your choice by checking the box, then click **Apply**.
4. Head back to the **Main** tab. After applying the changes, your configuration will have been reset.
5. Make any necessary changes to your configuration by assigning or unassigning disks as appropriate.
6. Launch the array in Normal or %%Maintenance Mode|maintenance-mode%% to finalize your updates.

:::important

- **Data preservation:** Unraid will attempt to recognize previously used drives and preserve data where possible.
- **Impact on parity:** Removing a data drive will always invalidate parity unless that drive was zeroed before removal.
- \*\*ä¿®å¤ç£ç›˜åˆ†é…é”™è¯¯ï¼š\*\*è§£å†³å½“å‰ç£ç›˜åˆ†é…çš„ä»»ä½•é—®é¢˜ã€‚

:::caution
When you see the **Start** button, there is a checkbox labeled **Parity is Valid**. Only check this box if you are certain it is correct or if an experienced Unraid user has advised you to do so during recovery. Incorrectly checking this option can lead to data loss.

å¦‚æœæ‚¨çš„ç›®æ ‡æ˜¯é‡å»ºç£ç›˜ï¼Œè¯·å‹¿ä½¿ç”¨ **New Config**ã€‚æ‰§è¡Œ New Config å°†æ¸…é™¤é‡å»ºæ‰€éœ€çš„é˜µåˆ—å†å²ï¼ŒUnraid å°†ä¸ä¼šæä¾›é‡å»ºç£ç›˜çš„é€‰é¡¹ã€‚è¯·æ”¹ä¸ºéµå¾ªç£ç›˜é‡å»ºç¨‹åºã€‚
:::

#### Undoing a reset

If you find that you need to reverse a reset:

1. Access your flash device over the network (SMB).
2. Locate and open the `config` folder.
3. Rename the file `super.old` to `super.dat`.
4. Reboot your server, and your prior array configuration should be restored.

---

### Status reports

Unraid provides status reports that help you keep track of the health of your storage array. These reports are a quick way to check if any of your disks are disabled or having issues with reading or writing data.

- **Current status:** Status reports show the current condition of your array. It's important to note that this information resets after you restart your system, so that it won't keep a history of past issues.

- **No historical data:** If you want to see what has happened before a reboot, you'll need to look elsewhere, as these reports don't save past states.

:::important
Remember that the status reports don't include %%SMART|smart%% data. %%SMART reports|smart-report%% give you a more detailed view of individual disk health. So, even if your status report shows everything is fine, checking the %%SMART reports|smart-report%% regularly is still a good idea to catch any potential problems early.
:::

---

## Array write modes

Unraid provides various write modes for managing array operations, each with its own pros and cons regarding speed, power consumption, and drive wear. Knowing how these modes work, along with the role of a cache drive or pool, can help you fine-tune your server to best suit your needs.

**Write modes at a glance**

| å†™å…¥æ¨¡å¼                      | é€Ÿåº¦ï¼ˆå…¸å‹ï¼‰                                   | Power usage | ä½•æ—¶é©±åŠ¨å™¨å¯åŠ¨                      | æ•°æ®ä¿æŠ¤             | æœ€ä½³ä½¿ç”¨åœºæ™¯                                                                |
| ------------------------- | ---------------------------------------- | ----------- | ---------------------------- | ---------------- | --------------------------------------------------------------------- |
| è¯»/ä¿®æ”¹/å†™                    | 20â€“40 MB/s                               | ä½           | Only parity and target drive | å¯ä»¥               | å¤§å¤šæ•°å·¥ä½œè´Ÿè½½ï¼ŒèŠ‚èƒ½ï¼Œå°å†™å…¥                                                        |
| Turbo Write (Reconstruct) | 40â€“120 MB/s                              | é«˜           | æ‰€æœ‰é©±åŠ¨å™¨                        | å¯ä»¥               | Large file transfers, array rebuilds, %%parity checks\|parity-check%% |
| ç¼“å­˜å†™å…¥ï¼ˆSSD/NVMeï¼‰            | 50â€“110 MB/s (SSD), 250â€“900 MB/s (NVMe)\* | å˜åŒ–          | ä»…ç¼“å­˜é©±åŠ¨å™¨                       | No (until moved) | åº”ç”¨ï¼Œè™šæ‹Ÿæœºï¼Œé¢‘ç¹å†™å…¥ï¼Œæœ€å¤§åŒ–é€Ÿåº¦                                                     |

<h3>Read/Modify/Write</h3>

<details>
  <summary>ç‚¹å‡»å±•å¼€/æŠ˜å </summary>

  <h4>å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„</h4>
  è¯¥æ¨¡å¼è¯»å–ç°æœ‰æ•°æ®å’Œæ ¡éªŒï¼Œè®¡ç®—æ–°çš„æ ¡éªŒï¼Œç„¶åå†™å…¥æ›´æ–°çš„æ•°æ®ã€‚åªæœ‰%%parity drive|parity-drives%%å’Œç›®æ ‡æ•°æ®é©±åŠ¨å™¨ä¸ä¹‹æ—‹è½¬ï¼Œä»è€Œé™ä½äº†åŠŸè€—å’Œé©±åŠ¨å™¨ç£¨æŸã€‚ç„¶è€Œï¼Œç”±äºé¢å¤–çš„è¯»/å†™å¾ªç¯ï¼Œå¯èƒ½ä¼šè¾ƒæ…¢ã€‚

  <h4>ä½¿ç”¨æ—¶æœº</h4>

  - Anytime, especially if you want energy savings and idle drives to spin down.
  - Great for small or infrequent writes.
</details>

<h3>Turbo Write (Reconstruct write)</h3>

<details>
  <summary>ç‚¹å‡»å±•å¼€/æŠ˜å </summary>

  Turbo write, also known as reconstruct write, is a feature designed to boost the writing speed of your Unraid array. It works by reading all data drives and updating the parity simultaneously. This process eliminates the delays caused by waiting for the platters to rotate, as seen in the default write mode. However, it's important to note that all array drives need to be spinning and functioning properly for this to work effectively.

  <h4>How it works</h4>

  - When you write new data, Unraid reads from all the other data drives and recalculates the parity at the same time. Both the new data and the updated parity get written together.
  - All drives in the array must be operational and actively spinning.
  - This method significantly enhances write speeds compared to the default writing mode.

  <h4>ä»€ä¹ˆæ—¶å€™ä½¿ç”¨Turbo Write</h4>

  - Utilize turbo write when transferring large, sequential files to the array.
  - It's effective during array rebuilds or %%parity checks|parity-check%%, as all drives will already be spinning.
  - This mode is very useful when minimizing write time is a priority and you can confirm all drives are healthy.

  <h4>ä»€ä¹ˆæ—¶å€™é¿å…ä½¿ç”¨Turbo Write</h4>

  - Avoid using this mode if you want your drives to spin down during idle times to conserve energy.
  - Turbo write isn't ideal for small or infrequent write operations since it causes all drives to spin up for every write, increasing power usage and wear on the drives.
  - If you suspect that any drive is failing or is unreliable, it's best to steer clear of turbo write since it relies on every drive being operational.

  :::ä¿¡æ¯
  Turboå†™å…¥æœ€é€‚åˆå¤§å®—æ“ä½œå’Œéœ€è¦é«˜ååé‡çš„åœºæ™¯ã€‚ç„¶è€Œï¼Œå¦‚æœæ‚¨å…³æ³¨èŠ‚èƒ½å’Œæœ€å°åŒ–é©±åŠ¨å™¨ç£¨æŸï¼Œå®ƒå¯èƒ½ä¸æ˜¯æ—¥å¸¸ä»»åŠ¡çš„æœ€ä½³é€‰æ‹©ã€‚
  :::
</details>

<h3>Cache Write</h3>

<details>
  <summary>ç‚¹å‡»å±•å¼€/æŠ˜å </summary>

  <h4>How it works</h4>

  æ•°æ®é¦–å…ˆå†™å…¥å¿«é€ŸSSDæˆ–NVMe %%cache|cache%%ï¼Œç„¶åé€šè¿‡ç§°ä¸º%%Mover|mover%%çš„è¿‡ç¨‹ç§»åŠ¨åˆ°ä¸»é˜µåˆ—ã€‚é€Ÿåº¦å¯å˜ï¼š

  - SSD: 50â€“110 MB/s
  - NVMe: 250â€“900 MB/s (which can utilize 10GbE networks)

  ä¸€æ—¦æ•°æ®è¢«ç§»åŠ¨åˆ°é˜µåˆ—ï¼Œå…¶å—åˆ°æ ¡æ£€ä¿æŠ¤ã€‚

  <h4>ä½¿ç”¨ç¼“å­˜å†™å…¥çš„æ—¶æœº</h4>

  - For shares with frequent write operations like applications, virtual machines, or downloads.
  - To enhance performance and reduce any perceived write latency.

  <h4>æ€§èƒ½é¢„æœŸ</h4>

  - Without a cache drive: Average 20â€“30 MB/s, with peaks up to 40 MB/s.
  - With SSD cache: 50â€“110 MB/s.
  - With NVMe cache: 250â€“900 MB/s depending on network or drive constraints.

  :::tip
  åœ¨%%Mover|mover%%è¿è¡Œä¹‹å‰ï¼Œè¯·è€ƒè™‘ä½¿ç”¨ç¼“å­˜æ± ï¼ˆå¤šä¸ªè®¾å¤‡ï¼‰ä»¥å¢åŠ å†—ä½™å’Œæ•°æ®ä¿æŠ¤ã€‚
  :::
</details>

:::info[Automated Solutions]

- The **Auto** mode (a future feature) will engage turbo write only when all drives are already spinning.
- ç¤¾åŒºæ’ä»¶ï¼ˆåœ¨åº”ç”¨ç¨‹åºé€‰é¡¹å¡ä¸­æœç´¢â€œTurbo Writeâ€ï¼‰å¯èƒ½æä¾›å¢å¼ºçš„è‡ªåŠ¨åŒ–æˆ–è°ƒåº¦é€‰é¡¹ã€‚
  :::

To change Write Mode:

1. Navigate to ***Settings â†’ Disk Settings***.
2. Locate **Tunable (md_write_method)**.
3. Choose your preferred mode:
   - **Read/Modify/Write** (default)
   - **Reconstruct Write** (Turbo Write)
   - **Auto** (future feature)
4. Click **Apply** to confirm your choice.

:::important[Quick recap]

- Use **Turbo Write** when you need speed, but be aware of increased power consumption and drive spin-up.
- Utilize **Cache Write** for optimal performance, particularly with SSD or NVMe drives.
- å¯¹äºå¤§å¤šæ•°ç”¨æˆ·ï¼Œé»˜è®¤å†™å…¥æ¨¡å¼æä¾›äº†æœ€ä½³å¹³è¡¡ï¼Œé™¤éæ‚¨ç‰¹åˆ«éœ€è¦æ›´é«˜é€Ÿåº¦ã€‚
  :::

---

## Read modes

When using Unraid, the speed at which you can read files is mainly determined by the individual drive that holds each file. Unlike traditional %%RAID|raid%% systems, which combine multiple drives to improve performance, Unraid stores each file on a single disk. This means read speeds won't be boosted by the combined speeds of multiple drives.

<h3>Performance expectations</h3>

- **Typical single HDD:** 70â€“250 MB/s (depends on drive model, age, and data location)
- **Typical SATA SSD:** 400â€“550 MB/s
- **NVMe SSD (in a pool):** 250â€“7,000 MB/s (PCIe generation and network/PCIe limitations apply; e.g., 10GbE network caps at ~1,100 MB/s)

:::note[Special cases]

- If a disk is disabled and its data is being reconstructed, Unraid will use the remaining drives along with parity information to recreate the data. During this process, the read speed may slow down to 30â€“60 MB/s or even lower, depending on the slowest drive in your system.
- é˜µåˆ—ä¸­çš„ä»»ä½•æ­£åœ¨è¿›è¡Œçš„æ“ä½œï¼Œä¾‹å¦‚ %%parity check|parity-check%% æˆ–ç£ç›˜é‡å»ºï¼Œå¯èƒ½ä¹Ÿä¼šå½±å“è¯»å–æ€§èƒ½ã€‚è¿™æ˜¯ç”±äºç£ç›˜ç£å¤´çš„ç§»åŠ¨å’Œèµ„æºçš„æ•´ä½“ç«äº‰å¢åŠ é€ æˆçš„ã€‚
  :::

---

## Cache pools

%%Cache pools|cache-pool%% in Unraid provide significant advantages, particularly for write-heavy tasks, virtual machines (VMs), and Docker containers. These pools operate separately from the main array and can be set up with multiple drives using either the %%BTRFS|btrfs%% or %%ZFS|zfs%% file system, supporting various %%RAID|raid%% configurations for speed and data protection.

<h3>Cache pools vs. the main array</h3>

| åŠŸèƒ½                      | ç¼“å­˜æ±  ï¼ˆBTRFSï¼‰                                                                                                      | ç¼“å­˜æ±  ï¼ˆZFSï¼‰                                                                                                                  | ä¸»é˜µåˆ—ï¼ˆUnraidï¼‰                                        |
| ----------------------- | ---------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------- |
| **è¯»å–é€Ÿåº¦**                | SSDï¼š400â€“550 MB/sï¼ŒNVMeï¼š250â€“7,000 MB/s\*                                                                           | SSDï¼š400â€“550 MB/sï¼ŒNVMeï¼š250â€“7,000 MB/s\*                                                                                     | HDDï¼š70â€“250 MB/sï¼ˆæ¯ä¸ªç£ç›˜ï¼‰                              |
| **å†™å…¥é€Ÿåº¦**                | SSDï¼š400â€“550 MB/sï¼ŒNVMeï¼š250â€“7,000 MB/s\*                                                                           | SSDï¼š400â€“550 MB/sï¼ŒNVMeï¼š250â€“7,000 MB/s\*                                                                                     | 20â€“120 MB/sï¼ˆå–å†³äºå¥‡å¶æ ¡éªŒæ¨¡å¼ï¼‰                             |
| **æ•°æ®ä¿æŠ¤**                | %%RAID 1\|raid1%%/%%RAID 10\|raid10%%; %%RAID 5\|raid5%%/%%RAID 6\|raid6%% (experimental, not for critical data) | %%RAID 1\|raid1%%/%%RAID 10\|raid10%%; %%RAIDZ1\|raidz1%%/%%RAIDZ2\|raidz2%%/%%RAIDZ3\|raidz3%% (stable, production-ready) | åŸºäºå¥‡å¶æ ¡éªŒï¼Œæ–‡ä»¶ç³»ç»Ÿæ— å…³                                      |
| **æ‰©å±•**                  | æ··åˆé©±åŠ¨å™¨å°ºå¯¸ï¼›åŠ¨æ€æ·»åŠ /åˆ é™¤è®¾å¤‡                                                                                                | Limited add/remove device support; cannot remove from RAIDZ; single-device add to expand single-vdev RAIDZ in Unraid 7.2   | Add drives, but no striping or performance scaling |
| **Recovery complexity** | æ•°æ®ä¸¢å¤±é£é™©è¾ƒé«˜ï¼›éœ€è¦%%BTRFS\|btrfs%%å·¥å…·                                                                                    | æ•°æ®ä¸¢å¤±é£é™©æ›´é«˜ï¼›éœ€è¦%%ZFS\|zfs%%å·¥å…·                                                                                                  | æ›´æ˜“åŸºäºå¥‡å¶æ ¡éªŒçš„é‡å»º                                        |
| **æœ€ä½³ç”¨é€”**                | åº”ç”¨ç¨‹åºã€VMsã€é¢‘ç¹å†™å…¥                                                                                                    | åº”ç”¨ç¨‹åºã€VMsã€é¢‘ç¹å†™å…¥ã€ä¼ä¸šå·¥ä½œè´Ÿè½½                                                                                                       | æ‰¹é‡å­˜å‚¨ã€åª’ä½“åº“                                           |

\**Actual NVMe speeds depend on PCIe generation, cooling, and network bandwidth (e.g., 10GbE caps at ~1,100 MB/s).*

<h4>Pros of cache pools</h4>

- **Higher performance:** NVMe pools can saturate 10GbE/40GbE networks (1,100â€“3,500 MB/s).
- **Flexible RAID:** Both %%BTRFS|btrfs%% and %%ZFS|zfs%% support %%RAID 1|raid1%%/%%RAID 10|raid10%% for redundancy without matching drive sizes.
- **Low latency:** Ideal for databases, VMs, and Docker containers.
- **ZFS advantages:** %%ZFS|zfs%% provides enterprise-grade features like data integrity checking, compression, and snapshots.

<h4>Cons of cache pools</h4>

- **No parity protection:** Data is unprotected until moved to the array.
- **Recovery risks:** %%BTRFS|btrfs%% %%RAID 5|raid5%%/%%RAID 6|raid6%% is unstable; single-drive pools lack redundancy.
- **ZFS considerations:** %%ZFS|zfs%% requires more RAM and has stricter hardware requirements than %%BTRFS|btrfs%%.

For more detailed information about %%cache pools|cache-pool%%, including how to set them up, manage them, and advanced features, check the [Cache pools](./cache-pools.mdx) page.

---

## æ•…éšœæ’é™¤

### Troubleshooting array start failures

If your array won't start, follow these steps to identify and fix common problems. Look for error messages under ***Main â†’ Array Operation***.

```mdx-code-block

<Tabs>
  <TabItem value="missing-disks" label="Missing disks" default>
    <TroubleshootMissingDisks />
  </TabItem>

  <TabItem value="device-limit" label="Device limit">
    <TroubleshootDeviceLimit />
  </TabItem>

  <TabItem value="key-issues" label="License issues">
    <TroubleshootLicenseIssues />
  </TabItem>

  <TabItem value="key-server" label="Key server connection">
    <TroubleshootKeyServer />
  </TabItem>

  <TabItem value="withdrawn" label="Withdrawn release">
    <TroubleshootWithdrawnRelease />
  </TabItem>
</Tabs>
```

### Disk failure during a rebuild

If a second disk fails while you're rebuilding another one, what you can do will depend on your parity setup.

<h4>Single %%parity disk|parity-drives%%</h4>

If one disk fails during the rebuild of another, the rebuild will stop because the data can't be accurately restored. Unfortunately, you won't be able to recover your data in this situation.

<h4>Dual %%parity disk|parity-drives%%</h4>

If you have two %%parity drives|parity-drives%%, you have more options:

- You can wait for the first rebuild to finish and then deal with the second failed disk.
- Or, you can stop the current rebuild, replace the second failed disk, and then start the array to rebuild both disks at the same time.

If the first rebuild is almost done, it's usually better to let it finish. If it just started, it might be faster to rebuild both together.

:::warning
Rebuilding disks puts a lot of stress on all drives, which increases the chance of new failures. Always check drive health using %%SMART reports|smart-report%% before starting a rebuild.
:::

:::info[Rebuild Time]
Be prepared for the rebuild process to take several hours. The time can vary based on disk size and how busy your system is. Larger disks and busy systems may take longer.
:::
